{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "21dcd583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from scripts.load_data import mapping, read_tsv_file, read_iob2_file\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c403a3",
   "metadata": {},
   "source": [
    "## Computing metrics for predictions on non-augmented and augmented test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eee77577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to data\n",
    "path_test = \"../data/no_overlap_da_news/da_news_test.tsv\"\n",
    "path_test_pred = \"predictions/test_pred.iob2\" \n",
    "path_me_test_pred = \"predictions/me_test_pred.iob2\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "adc8ee80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-LOC': 0, 'O': 1, 'I-ORG': 2, 'B-PER': 3, 'B-ORG': 4, 'I-LOC': 5, 'I-PER': 6, 'I-MISC': 7, 'B-MISC': 8}\n",
      "{0: 'B-LOC', 1: 'O', 2: 'I-ORG', 3: 'B-PER', 4: 'B-ORG', 5: 'I-LOC', 6: 'I-PER', 7: 'I-MISC', 8: 'B-MISC'}\n"
     ]
    }
   ],
   "source": [
    "# mapping labels\n",
    "label2id, id2label = mapping(path_test)\n",
    "\n",
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a9e0d3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in files\n",
    "test_data = read_tsv_file(path_test, label2id)\n",
    "test_pred = read_iob2_file(path_test_pred, label2id)\n",
    "me_test_pred = read_iob2_file(path_me_test_pred, label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3b543cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['I', '1983', 'ville', 'en', 'mand', 'have', 'navneforandring', 'til', 'Werwolf', ',', 'men', 'det', 'fik', 'han', 'ikke', 'lov', 'til', ',', 'for', 'det', 'betragtes', 'som', 'upassende', 'og', 'anstødeligt', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'tokens': ['I', '1983', 'ville', 'en', 'mand', 'have', 'navneforandring', 'til', 'Werwolf', ',', 'men', 'det', 'fik', 'han', 'ikke', 'lov', 'til', ',', 'for', 'det', 'betragtes', 'som', 'upassende', 'og', 'anstødeligt', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'tokens': ['I', '1983', 'ville', 'en', 'mand', 'have', 'navneforandring', 'til', 'Qasim', ',', 'men', 'det', 'fik', 'han', 'ikke', 'lov', 'til', ',', 'for', 'det', 'betragtes', 'som', 'upassende', 'og', 'anstødeligt', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# first sentence\n",
    "print(test_data[1])\n",
    "print(test_pred[1])\n",
    "print(me_test_pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "419ac311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# saving all true labels\n",
    "true_labels = []\n",
    "\n",
    "for sent in test_data:\n",
    "    true_labels.append(sent['ner_tags'])\n",
    "\n",
    "print(true_labels[1])\n",
    "print(len(true_labels) == len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e48324bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# saving all predicted labels\n",
    "pred_labels = []\n",
    "\n",
    "for sent in test_pred:\n",
    "    pred_labels.append(sent['ner_tags'])\n",
    "\n",
    "print(pred_labels[1])\n",
    "print(len(pred_labels) == len(test_data))\n",
    "\n",
    "# for ME predictions\n",
    "me_pred_labels = []\n",
    "\n",
    "for sent in me_test_pred:\n",
    "    me_pred_labels.append(sent['ner_tags'])\n",
    "\n",
    "print(me_pred_labels[1])\n",
    "print(len(me_pred_labels) == len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891697d8",
   "metadata": {},
   "source": [
    "## Non-augmented test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dbf0876b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.79%\n",
      "Recall: 0.73%\n",
      "F1: 0.76%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.79      0.82      0.81        91\n",
      "        MISC       0.48      0.22      0.30        63\n",
      "         ORG       0.72      0.66      0.69       122\n",
      "         PER       0.90      0.92      0.91       169\n",
      "\n",
      "   micro avg       0.79      0.73      0.76       445\n",
      "   macro avg       0.72      0.66      0.68       445\n",
      "weighted avg       0.77      0.73      0.74       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute precision, recall, and F1 score\n",
    "precision = precision_score(true_labels, pred_labels)\n",
    "recall = recall_score(true_labels, pred_labels)\n",
    "f1 = f1_score(true_labels, pred_labels)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1: {f1:.2f}%\")\n",
    "\n",
    "# optionally, print a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e17fc1",
   "metadata": {},
   "source": [
    "## Augmented test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0d3b5b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.71%\n",
      "Recall: 0.67%\n",
      "F1: 0.69%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.80      0.65      0.72        91\n",
      "        MISC       0.41      0.21      0.27        63\n",
      "         ORG       0.63      0.59      0.61       122\n",
      "         PER       0.78      0.91      0.84       169\n",
      "\n",
      "   micro avg       0.71      0.67      0.69       445\n",
      "   macro avg       0.65      0.59      0.61       445\n",
      "weighted avg       0.69      0.67      0.67       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute precision, recall, and F1 score\n",
    "precision = precision_score(true_labels, me_pred_labels)\n",
    "recall = recall_score(true_labels, me_pred_labels)\n",
    "f1 = f1_score(true_labels, me_pred_labels)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1: {f1:.2f}%\")\n",
    "\n",
    "# optionally, print a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, me_pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
