{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21dcd583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from scripts.load_data import mapping, read_tsv_file, read_iob2_file\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c403a3",
   "metadata": {},
   "source": [
    "## Computing metrics for predictions on non-augmented and augmented test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eee77577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to data\n",
    "path_test = \"../data/no_overlap_da_news/da_news_test.tsv\"\n",
    "path_test_pred = \"predictions/test_pred.iob2\" \n",
    "path_me_test = \"../data/me_data/middle_eastern_test.tsv\"\n",
    "path_me_test_pred = \"predictions/me_test_pred.iob2\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adc8ee80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ORG': 0, 'O': 1, 'I-PER': 2, 'B-MISC': 3, 'I-ORG': 4, 'B-PER': 5, 'I-LOC': 6, 'I-MISC': 7, 'B-LOC': 8}\n",
      "{0: 'B-ORG', 1: 'O', 2: 'I-PER', 3: 'B-MISC', 4: 'I-ORG', 5: 'B-PER', 6: 'I-LOC', 7: 'I-MISC', 8: 'B-LOC'}\n"
     ]
    }
   ],
   "source": [
    "# mapping labels\n",
    "label2id, id2label = mapping(path_test)\n",
    "\n",
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9e0d3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in files\n",
    "test_data = read_tsv_file(path_test, label2id)\n",
    "test_pred = read_iob2_file(path_test_pred, label2id)\n",
    "me_test_data = read_tsv_file(path_me_test, label2id)\n",
    "me_test_pred = read_iob2_file(path_me_test_pred, label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b543cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['I', '1983', 'ville', 'en', 'mand', 'have', 'navneforandring', 'til', 'Werwolf', ',', 'men', 'det', 'fik', 'han', 'ikke', 'lov', 'til', ',', 'for', 'det', 'betragtes', 'som', 'upassende', 'og', 'anstødeligt', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'tokens': ['I', '1983', 'ville', 'en', 'mand', 'have', 'navneforandring', 'til', 'Werwolf', ',', 'men', 'det', 'fik', 'han', 'ikke', 'lov', 'til', ',', 'for', 'det', 'betragtes', 'som', 'upassende', 'og', 'anstødeligt', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'tokens': ['I', '1983', 'ville', 'en', 'mand', 'have', 'navneforandring', 'til', 'Razia', ',', 'men', 'det', 'fik', 'han', 'ikke', 'lov', 'til', ',', 'for', 'det', 'betragtes', 'som', 'upassende', 'og', 'anstødeligt', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'tokens': ['I', '1983', 'ville', 'en', 'mand', 'have', 'navneforandring', 'til', 'Razia', ',', 'men', 'det', 'fik', 'han', 'ikke', 'lov', 'til', ',', 'for', 'det', 'betragtes', 'som', 'upassende', 'og', 'anstødeligt', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# first sentence\n",
    "print(test_data[1])\n",
    "print(test_pred[1])\n",
    "print(me_test_data[1])\n",
    "print(me_test_pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "419ac311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# saving all true labels\n",
    "true_labels = []\n",
    "\n",
    "for sent in test_data:\n",
    "    true_labels.append(sent['ner_tags'])\n",
    "\n",
    "print(true_labels[1])\n",
    "print(len(true_labels) == len(test_data))\n",
    "\n",
    "# saving all predicted labels\n",
    "pred_labels = []\n",
    "\n",
    "for sent in test_pred:\n",
    "    pred_labels.append(sent['ner_tags'])\n",
    "\n",
    "print(pred_labels[1])\n",
    "print(len(pred_labels) == len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e48324bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# for ME predictions\n",
    "me_true_labels = []\n",
    "\n",
    "for sent in me_test_data:\n",
    "    me_true_labels.append(sent['ner_tags'])\n",
    "\n",
    "print(me_true_labels[1])\n",
    "print(len(me_true_labels) == len(test_data))\n",
    "\n",
    "me_pred_labels = []\n",
    "\n",
    "for sent in me_test_pred:\n",
    "    me_pred_labels.append(sent['ner_tags'])\n",
    "\n",
    "print(me_pred_labels[1])\n",
    "print(len(me_pred_labels) == len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891697d8",
   "metadata": {},
   "source": [
    "## Non-augmented test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbf0876b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.82%\n",
      "Recall: 0.77%\n",
      "F1: 0.79%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.77      0.79      0.78        58\n",
      "        MISC       0.70      0.54      0.61        35\n",
      "         ORG       0.74      0.63      0.68        82\n",
      "         PER       0.92      0.92      0.92       118\n",
      "\n",
      "   micro avg       0.82      0.77      0.79       293\n",
      "   macro avg       0.78      0.72      0.75       293\n",
      "weighted avg       0.81      0.77      0.79       293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute precision, recall, and F1 score\n",
    "precision = precision_score(true_labels, pred_labels)\n",
    "recall = recall_score(true_labels, pred_labels)\n",
    "f1 = f1_score(true_labels, pred_labels)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1: {f1:.2f}%\")\n",
    "\n",
    "# optionally, print a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c296bd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall:    0.7705479452054794\n",
      "precision: 0.8302583025830258\n",
      "slot-f1:   0.7992895204262876\n",
      "\n",
      "unlabeled\n",
      "ul_recall:    0.8561643835616438\n",
      "ul_precision: 0.922509225092251\n",
      "ul_slot-f1:   0.8880994671403197\n",
      "\n",
      "loose (partial overlap with same label)\n",
      "l_recall:    0.7842465753424658\n",
      "l_precision: 0.8487084870848709\n",
      "l_slot-f1:   0.8152051942825745\n"
     ]
    }
   ],
   "source": [
    "!python span_f1.py ../data/no_overlap_da_news/da_news_test.iob2 predictions/test_pred.iob2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e17fc1",
   "metadata": {},
   "source": [
    "## Augmented test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d3b5b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.75%\n",
      "Recall: 0.71%\n",
      "F1: 0.73%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.75      0.71      0.73        58\n",
      "        MISC       0.45      0.51      0.48        35\n",
      "         ORG       0.79      0.54      0.64        82\n",
      "         PER       0.83      0.90      0.86       118\n",
      "\n",
      "   micro avg       0.75      0.71      0.73       293\n",
      "   macro avg       0.70      0.66      0.68       293\n",
      "weighted avg       0.75      0.71      0.73       293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute precision, recall, and F1 score\n",
    "precision = precision_score(me_true_labels, me_pred_labels)\n",
    "recall = recall_score(me_true_labels, me_pred_labels)\n",
    "f1 = f1_score(me_true_labels, me_pred_labels)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1: {f1:.2f}%\")\n",
    "\n",
    "# optionally, print a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(me_true_labels, me_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6bac2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall:    0.7123287671232876\n",
      "precision: 0.7482014388489209\n",
      "slot-f1:   0.7298245614035087\n",
      "\n",
      "unlabeled\n",
      "ul_recall:    0.8767123287671232\n",
      "ul_precision: 0.920863309352518\n",
      "ul_slot-f1:   0.8982456140350877\n",
      "\n",
      "loose (partial overlap with same label)\n",
      "l_recall:    0.7328767123287672\n",
      "l_precision: 0.7733812949640287\n",
      "l_slot-f1:   0.7525844019890081\n"
     ]
    }
   ],
   "source": [
    "!python span_f1.py ../data/me_data/middle_eastern_test.iob2 predictions/me_test_pred.iob2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
