{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21dcd583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from scripts.load_data import mapping, read_tsv_file, read_iob2_file\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c403a3",
   "metadata": {},
   "source": [
    "# Computing metrics for predictions on non-augmented test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eee77577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to data\n",
    "path_test = \"../data/da_news_new/new_da_news_test.tsv\"\n",
    "path_test_pred = \"../baseline/outputs/test_pred.iob2\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adc8ee80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-LOC': 0, 'O': 1, 'B-ORG': 2, 'I-PER': 3, 'I-MISC': 4, 'I-ORG': 5, 'B-MISC': 6, 'I-LOC': 7, 'B-PER': 8}\n",
      "{0: 'B-LOC', 1: 'O', 2: 'B-ORG', 3: 'I-PER', 4: 'I-MISC', 5: 'I-ORG', 6: 'B-MISC', 7: 'I-LOC', 8: 'B-PER'}\n"
     ]
    }
   ],
   "source": [
    "# mapping labels\n",
    "label2id, id2label = mapping(path_test)\n",
    "\n",
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9e0d3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in files\n",
    "test_data = read_tsv_file(path_test, label2id)\n",
    "test_pred = read_iob2_file(path_test_pred, label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b543cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['Under', 'rejser', 'og', 'ophold', 'i', 'udlandet', 'følger', 'sygeplejersker', 'og', 'hjælpere', 'med', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'tokens': ['Under', 'rejser', 'og', 'ophold', 'i', 'udlandet', 'følger', 'sygeplejersker', 'og', 'hjælpere', 'med', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# first sentence\n",
    "print(test_data[0])\n",
    "print(test_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "419ac311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# saving all true labels\n",
    "true_labels = []\n",
    "\n",
    "for sent in test_data:\n",
    "    true_labels.append(sent['ner_tags'])\n",
    "\n",
    "print(true_labels[0])\n",
    "print(len(true_labels) == len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e48324bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# saving all predicted labels\n",
    "pred_labels = []\n",
    "\n",
    "for sent in test_pred:\n",
    "    pred_labels.append(sent['ner_tags'])\n",
    "\n",
    "print(pred_labels[0])\n",
    "print(len(true_labels) == len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbf0876b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.77%\n",
      "Recall: 0.73%\n",
      "F1: 0.75%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.77      0.77      0.77        91\n",
      "        MISC       0.58      0.24      0.34        63\n",
      "         ORG       0.64      0.71      0.67       122\n",
      "         PER       0.91      0.89      0.90       169\n",
      "\n",
      "   micro avg       0.77      0.73      0.75       445\n",
      "   macro avg       0.72      0.65      0.67       445\n",
      "weighted avg       0.76      0.73      0.73       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute precision, recall, and F1 score\n",
    "precision = precision_score(true_labels, pred_labels)\n",
    "recall = recall_score(true_labels, pred_labels)\n",
    "f1 = f1_score(true_labels, pred_labels)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1: {f1:.2f}%\")\n",
    "\n",
    "# optionally, print a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
