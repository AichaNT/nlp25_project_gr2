{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06cb54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from scripts.load_data import label_mapping, extract_labeled_tokens, read_tsv_file, write_tsv_file, write_iob2_file\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "random.seed(20) # set seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef2fd6d",
   "metadata": {},
   "source": [
    "## Load original datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b7cbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the data files\n",
    "path_news_train = \"../data/da_news/da_news_train.tsv\"\n",
    "path_news_dev = \"../data/da_news/da_news_dev.tsv\"\n",
    "path_news_test = \"../data/da_news/da_news_test.tsv\"\n",
    "\n",
    "# create mapping\n",
    "label2id, id2label = label_mapping(path_news_train)\n",
    "\n",
    "# read in the DaN+ data\n",
    "train_data_news = read_tsv_file(path_news_train, label2id)\n",
    "dev_data_news = read_tsv_file(path_news_dev, label2id)\n",
    "test_data_news = read_tsv_file(path_news_test, label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "dd36e92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 4383\n",
      "dev size: 564\n",
      "test size: 565\n",
      "total dataset size: 5512\n"
     ]
    }
   ],
   "source": [
    "# dataset sizes\n",
    "print(\"train size:\", len(train_data_news))\n",
    "print(\"dev size:\", len(dev_data_news))\n",
    "print(\"test size:\", len(test_data_news))\n",
    "print(\"total dataset size:\", len(train_data_news) + len(dev_data_news) + len(test_data_news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "35ffd52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate datasets\n",
    "total_data = train_data_news + dev_data_news + test_data_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "f218abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraxt unique entities\n",
    "total_entities = extract_labeled_tokens(total_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce97ac14",
   "metadata": {},
   "source": [
    "## Build mapping from entity to sentence and sentence to entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "4144de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict with entities as keys and lists of sentence IDs as values\n",
    "entity_to_sents = defaultdict(set)\n",
    "sent_to_entities = defaultdict(set) # also creating mapping from sentence ID to entity\n",
    "\n",
    "for sent_id, sent in enumerate(total_data):\n",
    "\n",
    "    for tok_id, ent in enumerate(sent[\"tokens\"]):\n",
    "\n",
    "        if ent in total_entities and sent['ner_tags'][tok_id] != 'O':\n",
    "\n",
    "            entity_to_sents[ent].add(sent_id)\n",
    "\n",
    "            sent_to_entities[sent_id].add(ent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc89defe",
   "metadata": {},
   "source": [
    "## Group sentences by overlapping entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "40ecab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group sentences by shared entities\n",
    "\n",
    "visited = set()\n",
    "sentence_groups = []\n",
    "\n",
    "for sent_id in sent_to_entities:\n",
    "\n",
    "    if sent_id in visited:\n",
    "        continue\n",
    "\n",
    "    group, queue = set(), [sent_id]\n",
    "\n",
    "    while queue:\n",
    "\n",
    "        current = queue.pop()\n",
    "\n",
    "        if current in visited:\n",
    "            continue\n",
    "\n",
    "        visited.add(current)\n",
    "        group.add(current)\n",
    "\n",
    "        for entity in sent_to_entities[current]:\n",
    "\n",
    "            queue.extend(entity_to_sents[entity])\n",
    "\n",
    "    sentence_groups.append(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "7abb0996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and split groups by total sentence count\n",
    "\n",
    "random.shuffle(sentence_groups)\n",
    "\n",
    "train_group, dev_group, test_group, count = [], [], [], 0\n",
    "total = sum(len(g) for g in sentence_groups)\n",
    "train_cutoff, dev_cutoff = int(total * 0.8), int(total * 0.9)\n",
    "\n",
    "for group in sentence_groups:\n",
    "\n",
    "    if count < train_cutoff:\n",
    "        train_group += group\n",
    "        \n",
    "    elif count < dev_cutoff:\n",
    "        dev_group += group\n",
    "\n",
    "    else:\n",
    "        test_group += group\n",
    "\n",
    "    count += len(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c43bca8",
   "metadata": {},
   "source": [
    "## Add sentences with only 'O' tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "13f40576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add unused sentences with all 'O' tags\n",
    "used = set(train_group + dev_group + test_group)\n",
    "o_tagged = []\n",
    "\n",
    "for idx, sent in enumerate(total_data):\n",
    "    if idx not in used and all(tag == \"O\" for tag in sent[\"ner_tags\"]):\n",
    "        o_tagged.append(idx)\n",
    "\n",
    "random.shuffle(o_tagged)\n",
    "\n",
    "cut1, cut2 = int(len(o_tagged) * 0.8), int(len(o_tagged) * 0.9)\n",
    "\n",
    "train_group += o_tagged[:cut1]\n",
    "dev_group += o_tagged[cut1:cut2]\n",
    "test_group += o_tagged[cut2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "e2dcace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final splits\n",
    "train_data = [total_data[i] for i in sorted(train_group)]\n",
    "dev_data = [total_data[i] for i in sorted(dev_group)]\n",
    "test_data = [total_data[i] for i in sorted(test_group)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49301886",
   "metadata": {},
   "source": [
    "## Check sizes and overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "293968f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 4411\n",
      "dev size: 549\n",
      "test size: 552\n",
      "total dataset size: 5512\n"
     ]
    }
   ],
   "source": [
    "# sizes of new datasets\n",
    "print(\"train size:\", len(train_data))\n",
    "print(\"dev size:\", len(dev_data))\n",
    "print(\"test size:\", len(test_data))\n",
    "print(\"total dataset size:\", len(train_data) + len(dev_data) + len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "9feb5565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract tokens with non-\"O\" labels from each split\n",
    "train_tokens = extract_labeled_tokens(train_data)\n",
    "dev_tokens = extract_labeled_tokens(dev_data)\n",
    "test_tokens = extract_labeled_tokens(test_data)\n",
    "\n",
    "# overlap between datasets\n",
    "train_dev_overlap = train_tokens & dev_tokens\n",
    "dev_test_overlap = dev_tokens & test_tokens\n",
    "train_test_overlap = train_tokens & test_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "d792edb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap between train and dev: 0\n",
      "overlap between dev and test: 0\n",
      "overlap between train and test: 0\n"
     ]
    }
   ],
   "source": [
    "# check for overlap between datasets\n",
    "print('overlap between train and dev:', len(train_dev_overlap))\n",
    "print('overlap between dev and test:', len(dev_test_overlap))\n",
    "print('overlap between train and test:', len(train_test_overlap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe09a24",
   "metadata": {},
   "source": [
    "## Look at distribution of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "bf67cff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'I-PER': 598, 'B-PER': 521, 'B-ORG': 481, 'B-LOC': 398, 'I-ORG': 329, 'I-MISC': 219, 'B-MISC': 195, 'I-LOC': 64})\n",
      "Counter({'B-PER': 73, 'B-ORG': 73, 'B-LOC': 55, 'B-MISC': 48, 'I-PER': 27, 'I-ORG': 20, 'I-MISC': 16, 'I-LOC': 7})\n",
      "Counter({'B-PER': 90, 'B-ORG': 74, 'B-LOC': 47, 'I-PER': 44, 'B-MISC': 33, 'I-ORG': 28, 'I-MISC': 12, 'I-LOC': 5})\n"
     ]
    }
   ],
   "source": [
    "train_tokens = extract_labeled_tokens(train_data, include_label_pair=True)\n",
    "dev_tokens = extract_labeled_tokens(dev_data, include_label_pair=True)\n",
    "test_tokens = extract_labeled_tokens(test_data, include_label_pair=True)\n",
    "\n",
    "train_distr = Counter(tag for _, tag in train_tokens)\n",
    "test_distr = Counter(tag for _, tag in test_tokens)\n",
    "dev_distr = Counter(tag for _, tag in dev_tokens)\n",
    "\n",
    "print(train_distr)\n",
    "print(dev_distr)\n",
    "print(test_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "091a92ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Percentage Distribution:\n",
      "{'I-ORG': 11.73, 'I-PER': 21.32, 'I-MISC': 7.81, 'B-MISC': 6.95, 'I-LOC': 2.28, 'B-PER': 18.57, 'B-ORG': 17.15, 'B-LOC': 14.19}\n",
      "\n",
      "Dev Percentage Distribution:\n",
      "{'I-ORG': 6.27, 'I-PER': 8.46, 'B-MISC': 15.05, 'B-PER': 22.88, 'B-ORG': 22.88, 'B-LOC': 17.24, 'I-MISC': 5.02, 'I-LOC': 2.19}\n",
      "\n",
      "Test Percentage Distribution:\n",
      "{'B-PER': 27.03, 'B-MISC': 9.91, 'B-ORG': 22.22, 'I-ORG': 8.41, 'I-PER': 13.21, 'B-LOC': 14.11, 'I-MISC': 3.6, 'I-LOC': 1.5}\n"
     ]
    }
   ],
   "source": [
    "def get_percentage_distribution(counter):\n",
    "    total = sum(counter.values())\n",
    "    return {tag: round((count / total) * 100, 2) for tag, count in counter.items()}\n",
    "\n",
    "# calculate percentage distributions\n",
    "train_percent = get_percentage_distribution(train_distr)\n",
    "dev_percent = get_percentage_distribution(dev_distr)\n",
    "test_percent = get_percentage_distribution(test_distr)\n",
    "\n",
    "# print results\n",
    "print(\"Train Percentage Distribution:\")\n",
    "print(train_percent)\n",
    "print(\"\\nDev Percentage Distribution:\")\n",
    "print(dev_percent)\n",
    "print(\"\\nTest Percentage Distribution:\")\n",
    "print(test_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3739ad2",
   "metadata": {},
   "source": [
    "## Check overlap and label distribution in ME data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "2aa731c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap between train and ME_dev: 0\n",
      "overlap between train and ME_test: 0\n",
      "overlap between ME_dev and ME_test: 41\n"
     ]
    }
   ],
   "source": [
    "## checking for ME data ##\n",
    "\n",
    "# path to the data files\n",
    "path_me_dev = \"../data/me_data/middle_eastern_dev.tsv\"\n",
    "path_me_test = \"../data/me_data/middle_eastern_test.tsv\"\n",
    "\n",
    "# read in the data\n",
    "me_dev_data = read_tsv_file(path_me_dev, label2id)\n",
    "me_test_data = read_tsv_file(path_me_test, label2id)\n",
    "\n",
    "# extract labels\n",
    "me_dev_tokens = extract_labeled_tokens(me_dev_data)\n",
    "me_test_tokens = extract_labeled_tokens(me_test_data)\n",
    "\n",
    "# overlap between datasets\n",
    "me_train_dev_overlap = train_tokens & me_dev_tokens\n",
    "me_train_test_overlap = train_tokens & me_test_tokens\n",
    "me_dev_test_overlap = me_dev_tokens & me_test_tokens\n",
    "\n",
    "print('overlap between train and ME_dev:', len(me_train_dev_overlap))\n",
    "print('overlap between train and ME_test:', len(me_train_test_overlap))\n",
    "print('overlap between ME_dev and ME_test:', len(me_dev_test_overlap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "9a9c3b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'B-PER': 94, 'B-ORG': 71, 'B-LOC': 66, 'B-MISC': 48, 'I-PER': 30, 'I-ORG': 18, 'I-MISC': 16, 'I-LOC': 8})\n",
      "Counter({'B-PER': 117, 'B-ORG': 66, 'B-LOC': 54, 'I-PER': 53, 'B-MISC': 33, 'I-ORG': 26, 'I-MISC': 12, 'I-LOC': 5})\n"
     ]
    }
   ],
   "source": [
    "me_dev_tokens = extract_labeled_tokens(me_dev_data, include_label_pair=True)\n",
    "me_test_tokens = extract_labeled_tokens(me_test_data, include_label_pair=True)\n",
    "\n",
    "me_test_distr = Counter(tag for _, tag in me_test_tokens)\n",
    "me_dev_distr = Counter(tag for _, tag in me_dev_tokens)\n",
    "\n",
    "print(me_dev_distr)\n",
    "print(me_test_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "79c218b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Bagdad', 'B-LOC')}\n"
     ]
    }
   ],
   "source": [
    "test_tokens = extract_labeled_tokens(test_data, include_label_pair=True)\n",
    "me_test_tokens = extract_labeled_tokens(me_test_data, include_label_pair=True)\n",
    "\n",
    "# Get tokens where the label is not 'MISC'\n",
    "non_misc_overlap = {(token, label) for token, label in (test_tokens & me_test_tokens) if label not in ['B-MISC', 'I-MISC']}\n",
    "\n",
    "print(non_misc_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122a4e97",
   "metadata": {},
   "source": [
    "## Write to tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "219b29bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv_file(train_data, '../data/no_overlap_da_news/da_news_train.tsv')\n",
    "write_tsv_file(dev_data, '../data/no_overlap_da_news/da_news_dev.tsv')\n",
    "write_tsv_file(test_data, '../data/no_overlap_da_news/da_news_test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "eb598165",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_iob2_file(test_data, path=\"../data/no_overlap_da_news/da_news_test.iob2\", gold=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
