{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70c7971d",
   "metadata": {},
   "source": [
    "Intended structure\n",
    "1. imports\n",
    "2. get data\n",
    "    - define path\n",
    "    - create label mapping\n",
    "    - read in DaN+ data\n",
    "    - check set sizes (?)\n",
    "    - get tokens (?)\n",
    "    - check num tokens in sets (?)\n",
    "    - check overlap (sanity check instead?)\n",
    "\n",
    "3. fix overlap\n",
    "    - check set sizes (?)\n",
    "    - check overlap (sanity check instead?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e95adf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append('.')  # add the project root to the path\n",
    "\n",
    "from scripts.load_data import (\n",
    "    label_mapping, extract_labeled_tokens,\n",
    "    read_tsv_file, write_tsv_file,\n",
    "    write_iob2_file, modified_readNlu,\n",
    "    read_iob2_file\n",
    ")\n",
    "\n",
    "from scripts.preprocess import (\n",
    "    fix_overlap, check_dataset_sizes,\n",
    "    check_token_overlap\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee8b547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the data files\n",
    "path_train = \"data/da_news/da_news_train.tsv\"\n",
    "path_dev = \"data/da_news/da_news_dev.tsv\"\n",
    "path_test = \"data/da_news/da_news_test.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f004af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create label mapping\n",
    "label2id, id2label = label_mapping(path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "571ee32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the DaN+ data\n",
    "train_data = read_tsv_file(path_train, label2id)\n",
    "dev_data = read_tsv_file(path_dev, label2id)\n",
    "test_data = read_tsv_file(path_test, label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d3c6a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 4383\n",
      "dev size: 564\n",
      "test size: 565\n",
      "total dataset size: 5512\n"
     ]
    }
   ],
   "source": [
    "# dataset sizes\n",
    "check_dataset_sizes(train_data, dev_data, test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ee2e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract tokens with non-\"O\" labels from each split\n",
    "train_tokens = extract_labeled_tokens(train_data)\n",
    "dev_tokens = extract_labeled_tokens(dev_data)\n",
    "test_tokens = extract_labeled_tokens(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "805ea3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokes in train : 2635 tokens\n",
      "Unique tokes in dev : 470 tokens\n",
      "Unique tokes in test : 513 tokens\n"
     ]
    }
   ],
   "source": [
    "# print out the number of unique tokens in each split\n",
    "print(f\"Unique tokes in train : {len(train_tokens)} tokens\")\n",
    "print(f\"Unique tokes in dev : {len(dev_tokens)} tokens\")\n",
    "print(f\"Unique tokes in test : {len(test_tokens)} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ceee5319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap between train and dev: 256\n",
      "overlap between dev and test: 78\n",
      "overlap between train and test: 219\n"
     ]
    }
   ],
   "source": [
    "check_token_overlap(train_data, dev_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acabd15e",
   "metadata": {},
   "source": [
    "Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b02c503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix overlap\n",
    "clean_train_data, clean_dev_data, clean_test_data = fix_overlap(train_data, dev_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab2e7fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 4519\n",
      "dev size: 443\n",
      "test size: 550\n",
      "total dataset size: 5512\n"
     ]
    }
   ],
   "source": [
    "check_dataset_sizes(clean_train_data, clean_dev_data, clean_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1022a230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap between train and dev: 0\n",
      "overlap between dev and test: 0\n",
      "overlap between train and test: 0\n"
     ]
    }
   ],
   "source": [
    "check_token_overlap(clean_train_data, clean_dev_data, clean_test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
