{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e95adf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append('.')  # add the project root to the path\n",
    "\n",
    "from scripts.load_data import (\n",
    "    label_mapping, extract_labeled_tokens,\n",
    "    read_tsv_file, write_tsv_file,\n",
    "    write_iob2_file, modified_readNlu,\n",
    "    read_iob2_file\n",
    ")\n",
    "\n",
    "from scripts.preprocess import (\n",
    "    concatenate_data, enitity_sentence_mapping,\n",
    "    group_sentences, split_sentence_groups,\n",
    "    finalize_split_with_o_sentences,\n",
    "    check_dataset_sizes, check_token_overlap,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee8b547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the data files\n",
    "path_train = \"data/da_news/da_news_train.tsv\"\n",
    "path_dev = \"data/da_news/da_news_dev.tsv\"\n",
    "path_test = \"data/da_news/da_news_test.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f004af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create label mapping\n",
    "label2id, id2label = label_mapping(path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "571ee32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the DaN+ data\n",
    "train_data = read_tsv_file(path_train, label2id)\n",
    "dev_data = read_tsv_file(path_dev, label2id)\n",
    "test_data = read_tsv_file(path_test, label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ee2e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract tokens with non-\"O\" labels from each split\n",
    "train_tokens = extract_labeled_tokens(train_data)\n",
    "dev_tokens = extract_labeled_tokens(dev_data)\n",
    "test_tokens = extract_labeled_tokens(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "805ea3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokes in train : 2635 tokens\n",
      "Unique tokes in dev : 470 tokens\n",
      "Unique tokes in test : 513 tokens\n"
     ]
    }
   ],
   "source": [
    "# print out the number of unique tokens in each split\n",
    "print(f\"Unique tokes in train : {len(train_tokens)} tokens\")\n",
    "print(f\"Unique tokes in dev : {len(dev_tokens)} tokens\")\n",
    "print(f\"Unique tokes in test : {len(test_tokens)} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a0dfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Dev overlap: 256 tokens\n",
      "Train-Test overlap: 219 tokens\n",
      "Dev-Test overlap: 78 tokens\n",
      "All three overlap: 74 tokens\n"
     ]
    }
   ],
   "source": [
    "# compute intersections to find overlaps\n",
    "train_dev_overlap = train_tokens & dev_tokens                   # tokens that appear in both train and dev\n",
    "train_test_overlap = train_tokens & test_tokens                 # tokens that appear in both train and test\n",
    "dev_test_overlap = dev_tokens & test_tokens                     # tokens that appear in both dev and test\n",
    "all_three_overlap = train_tokens & dev_tokens & test_tokens     # tokens common to all three splits\n",
    "\n",
    "# print out the number of overlapping tokens\n",
    "print(f\"Train-Dev overlap: {len(train_dev_overlap)} tokens\")\n",
    "print(f\"Train-Test overlap: {len(train_test_overlap)} tokens\")\n",
    "print(f\"Dev-Test overlap: {len(dev_test_overlap)} tokens\")\n",
    "print(f\"All three overlap: {len(all_three_overlap)} tokens\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acabd15e",
   "metadata": {},
   "source": [
    "Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "535e4793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate data\n",
    "total_data = concatenate_data(train_data, dev_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79cc9022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all unique non-\"O\" entities\n",
    "total_entities = extract_labeled_tokens(total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bd864cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create entity sentence mapping\n",
    "entity_to_sents, sent_to_entities = enitity_sentence_mapping(total_data, total_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9878645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group sentences by shared entities\n",
    "sentence_groups = group_sentences(entity_to_sents, sent_to_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caf5cff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and split groups by total sentence count\n",
    "train_group, dev_group, test_group = split_sentence_groups(sentence_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9d7a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get final slipts (with all \"O\" sentences)\n",
    "train_data, dev_data, test_data = finalize_split_with_o_sentences(total_data, train_group, dev_group, test_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab2e7fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 4181\n",
      "dev size: 326\n",
      "test size: 327\n",
      "total dataset size: 4834\n"
     ]
    }
   ],
   "source": [
    "check_dataset_sizes(train_data, dev_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1022a230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap between train and dev: 0\n",
      "overlap between dev and test: 0\n",
      "overlap between train and test: 0\n"
     ]
    }
   ],
   "source": [
    "check_token_overlap(train_data, dev_data, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
