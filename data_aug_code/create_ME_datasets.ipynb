{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "d0eae3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import random\n",
    "import copy\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from scripts.load_data import write_tsv_file, extract_labeled_tokens, mapping, read_tsv_file, write_iob2_file\n",
    "from middle_eastern_ne import extract_first_names, get_last_names,  load_location, load_organisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbdc040",
   "metadata": {},
   "source": [
    "## Get ME entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "c6bf85f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ME_BPER = extract_first_names(\"../data_aug_sources/Ordbog_over_muslimske_fornavne_i_DK.pdf\")\n",
    "ME_IPER = get_last_names(\"../data_aug_sources/middle_eastern_last_names.txt\", \"../data_aug_sources/KDBGIVE.tsv\")\n",
    "ME_LOC = load_location(\"../data_aug_sources/the-middle-east-cities.csv\")\n",
    "ME_ORG = load_organisation(\"../data_aug_sources/middle_eastern_organisations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "8d14fffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['Saudi', 'Aramco'], 'ner_tags': ['B-ORG', 'I-ORG']}"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ME_ORG[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07d846a",
   "metadata": {},
   "source": [
    "## Read in data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "2f38682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the data files\n",
    "path_train = \"../data/no_overlap_da_news/da_news_train.tsv\"\n",
    "path_dev = \"../data/no_overlap_da_news/da_news_dev.tsv\"\n",
    "path_test = \"../data/no_overlap_da_news/da_news_test.tsv\"\n",
    "\n",
    "# create mapping\n",
    "label2id, id2label = mapping(path_train)\n",
    "\n",
    "# read in the DaN+ data\n",
    "train_data = read_tsv_file(path_train, label2id)\n",
    "dev_data = read_tsv_file(path_dev, label2id)\n",
    "test_data = read_tsv_file(path_test, label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d447948f",
   "metadata": {},
   "source": [
    "## Replace entities in dev and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "ac413feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting all tokens in train data - to ensure no overlap later\n",
    "train_tokens = extract_labeled_tokens(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "fbf776a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for saving all used entities\n",
    "used_entities = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "26cec93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_aug_replace(dataset, sentence_amount, ME_LOC = ME_LOC, ME_ORG = ME_ORG,\n",
    "                     ME_BPER = ME_BPER, ME_IPER = ME_IPER, used_entities = used_entities, train_tokens=train_tokens):\n",
    "    \"\"\"\n",
    "    Replaces named entities in a subset of the dataset with new MENAPT ones, ensuring no reuse across datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    random.seed(42)\n",
    "\n",
    "    # extract sentences with containing relevant tags\n",
    "    eligible_sentences = [sent for sent in dataset if any(tag not in [\"O\", \"B-MISC\", \"I-MISC\"] for tag in sent[\"ner_tags\"])]\n",
    "    # select random sentences\n",
    "    selected_sentences = random.sample(eligible_sentences, min(sentence_amount, len(eligible_sentences)))\n",
    "    # create copy to not modify original dataset \n",
    "    modified_dataset = [dict(sent) for sent in dataset] \n",
    "\n",
    "    for sent in modified_dataset:\n",
    "        if sent not in selected_sentences:\n",
    "            continue\n",
    "\n",
    "        i = 0\n",
    "        while i < len(sent[\"tokens\"]):\n",
    "            tag = sent[\"ner_tags\"][i]\n",
    "\n",
    "            if tag == 'B-PER':\n",
    "                available = [p for p in ME_BPER if p not in used_entities and p not in train_tokens]\n",
    "                if available:\n",
    "                    replace = random.choice(available)\n",
    "                    sent[\"tokens\"][i] = replace\n",
    "                    used_entities.add(replace)\n",
    "                i += 1\n",
    "\n",
    "            elif tag == 'I-PER':\n",
    "                available = [p for p in ME_IPER if p not in used_entities and p not in train_tokens]\n",
    "                if available:\n",
    "                    replace = random.choice(available)\n",
    "                    sent[\"tokens\"][i] = replace\n",
    "                    used_entities.add(replace)\n",
    "                i += 1\n",
    "\n",
    "            elif tag == 'B-LOC':\n",
    "                span_start = i\n",
    "                span_len = 1\n",
    "\n",
    "                i += 1\n",
    "\n",
    "                while i < len(sent[\"ner_tags\"]) and sent[\"ner_tags\"][i] == \"I-LOC\":\n",
    "                    span_len += 1\n",
    "                    i += 1\n",
    "\n",
    "                available = [\n",
    "                    loc for loc in ME_LOC\n",
    "                    if not any(token in train_tokens for token in loc[\"tokens\"])\n",
    "                    and not any(token in used_entities for token in loc[\"tokens\"])\n",
    "                    and len(loc[\"tokens\"]) == span_len\n",
    "                ]\n",
    "                \n",
    "                if available:\n",
    "                    replace = random.choice(available)\n",
    "                    sent[\"tokens\"][span_start:span_start + span_len] = replace[\"tokens\"]\n",
    "                    used_entities.update(replace[\"tokens\"])\n",
    "\n",
    "            elif tag == 'B-ORG':\n",
    "                span_start = i\n",
    "                span_len = 1\n",
    "                i += 1\n",
    "                while i < len(sent[\"ner_tags\"]) and sent[\"ner_tags\"][i] == \"I-ORG\":\n",
    "                    span_len += 1\n",
    "                    i += 1\n",
    "\n",
    "                available = [\n",
    "                    org for org in ME_ORG\n",
    "                    if not any(token in train_tokens for token in org[\"tokens\"])\n",
    "                    and not any(token in used_entities for token in org[\"tokens\"])\n",
    "                    and len(org[\"tokens\"]) == span_len\n",
    "                ]\n",
    "\n",
    "                if available:\n",
    "                    replace = random.choice(available)\n",
    "                    sent[\"tokens\"][span_start:span_start + span_len] = replace[\"tokens\"]\n",
    "                    used_entities.update(replace[\"tokens\"])\n",
    "\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "    return modified_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "c07f7a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_aug_replace(dataset, sentence_amount, ME_LOC = ME_LOC, ME_ORG = ME_ORG,\n",
    "                     ME_BPER = ME_BPER, ME_IPER = ME_IPER, used_entities = None, train_tokens=train_tokens):\n",
    "    \"\"\"\n",
    "    Replaces named entities in a subset of the dataset with new MENAPT ones, ensuring:\n",
    "    - No reused tokens across datasets\n",
    "    - No tokens from train set\n",
    "    - Deterministic behavior\n",
    "    - Returns updated used_entities (flat set of tokens)\n",
    "    \"\"\"\n",
    "    random.seed(42)\n",
    "    local_used = set(used_entities)\n",
    "    modified_dataset = [dict(sent) for sent in dataset]\n",
    "\n",
    "    eligible_sentences = [\n",
    "        sent for sent in modified_dataset\n",
    "        if any(tag not in [\"O\", \"B-MISC\", \"I-MISC\"] for tag in sent[\"ner_tags\"])\n",
    "    ]\n",
    "    selected_sentences = random.sample(eligible_sentences, min(sentence_amount, len(eligible_sentences)))\n",
    "\n",
    "    for sent in modified_dataset:\n",
    "        if sent not in selected_sentences:\n",
    "            continue\n",
    "\n",
    "        i = 0\n",
    "        while i < len(sent[\"tokens\"]):\n",
    "            tag = sent[\"ner_tags\"][i]\n",
    "\n",
    "            if tag == 'B-PER':\n",
    "                available = [p for p in ME_BPER if p not in local_used and p not in train_tokens]\n",
    "                if available:\n",
    "                    replace = random.choice(available)\n",
    "                    sent[\"tokens\"][i] = replace\n",
    "                    local_used.add(replace)\n",
    "                i += 1\n",
    "\n",
    "            elif tag == 'I-PER':\n",
    "                available = [p for p in ME_IPER if p not in local_used and p not in train_tokens]\n",
    "                if available:\n",
    "                    replace = random.choice(available)\n",
    "                    sent[\"tokens\"][i] = replace\n",
    "                    local_used.add(replace)\n",
    "                i += 1\n",
    "\n",
    "            elif tag == 'B-LOC':\n",
    "                span_start = i\n",
    "                span_len = 1\n",
    "                i += 1\n",
    "                while i < len(sent[\"ner_tags\"]) and sent[\"ner_tags\"][i] == \"I-LOC\":\n",
    "                    span_len += 1\n",
    "                    i += 1\n",
    "\n",
    "                available = [\n",
    "                    loc for loc in ME_LOC\n",
    "                    if len(loc[\"tokens\"]) == span_len and\n",
    "                    all(tok not in train_tokens and tok not in local_used for tok in loc[\"tokens\"])\n",
    "                ]\n",
    "                if available:\n",
    "                    replace = random.choice(available)\n",
    "                    sent[\"tokens\"][span_start:span_start + span_len] = replace[\"tokens\"]\n",
    "                    local_used.update(replace[\"tokens\"])\n",
    "\n",
    "            elif tag == 'B-ORG':\n",
    "                span_start = i\n",
    "                span_len = 1\n",
    "                i += 1\n",
    "                while i < len(sent[\"ner_tags\"]) and sent[\"ner_tags\"][i] == \"I-ORG\":\n",
    "                    span_len += 1\n",
    "                    i += 1\n",
    "\n",
    "                available = [\n",
    "                    org for org in ME_ORG\n",
    "                    if len(org[\"tokens\"]) == span_len and\n",
    "                    all(tok not in train_tokens and tok not in local_used for tok in org[\"tokens\"])\n",
    "                ]\n",
    "                if available:\n",
    "                    replace = random.choice(available)\n",
    "                    sent[\"tokens\"][span_start:span_start + span_len] = replace[\"tokens\"]\n",
    "                    local_used.update(replace[\"tokens\"])\n",
    "\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "    return modified_dataset, local_used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "0473ac72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "6025d8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ME_dev, used_entities = data_aug_replace(dev_data, used_entities=used_entities, sentence_amount=1000)\n",
    "len(used_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "fe68fcbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "865"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ME_test, used_entities = data_aug_replace(test_data, used_entities=used_entities, sentence_amount=1000)\n",
    "len(used_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "75b7f975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fares', 'Hamoud', 'Aqaba', 'Empower', 'Büyükçekmece', 'Americana', 'Al-Kifah', 'Izmit', 'Properties', 'SNVI', 'Asdaa', 'Sohar', 'Ghada', 'Mrsool', 'Salama', 'Nazir', 'by', 'Damietta', 'Laila', 'Burson', 'Cinescape', 'Anis', 'Mawdoo3', 'Faisa', 'Kadir', 'Sarwa', 'Ahar', 'OSN', 'SGTM', 'Talabat', 'KSA', 'Sheikh', \"'Amarah\", 'Ad-Dustour', 'Ahmed', 'Mehwar', 'Aldhiayni', 'ADNOC', 'RASCO', 'Damac', 'Söke', 'Yasuj', 'Shorooq', 'Manna', 'Spinneys', 'Rim', 'Silopi', 'Naima', 'Al-Ahd', 'Aydin', 'Raad', 'Husam', 'Sancaktepe', 'Al kibaly', 'Basil', 'Rafah', 'Jalil', 'Mushait', 'Mustapha', 'Shabnam', 'Marafiq', 'Qorveh', 'Dahir', 'Faiza', 'Shamsina', 'Electroplanet', 'Tabuk', 'Polisario', 'Samir', 'Kirkuk', 'Education', 'Tabbah', 'Riyadh', 'Viranşehir', 'Gonbad-e', 'Ilyas', 'Partners', 'Zeina', 'Al-Thawra', 'Jamal', 'Azad', 'Jasmina', 'Polatlı', 'Hilmi', 'Alnawaflh', 'Alaijaybi', 'stc', 'Metin', 'Kudu', 'Imane', 'Obeidat', 'Etisalat', 'Salem', 'PSLab', 'Ola', 'SPORTS', 'Ammar', 'Jidda', 'Yasemin', 'Eissa', 'Heba', 'Hebron', 'Mersin', 'Dahlia', 'Alexandria', 'Khawaldeh', 'Fayad', 'Mahabad', 'Samar', 'Chaudhry', 'NBN', 'Alaitayli', 'Ashraf', 'Amal', 'Aziz', 'Khartoum', 'Niğde', 'Kahta', 'Mehmet', 'Assia', 'Yasir', 'Air', 'Development', 'Manea', 'Epilert', 'Ubah', 'Amol', 'Kastamonu', 'Sofia', 'TGCC', 'Mohamad', 'Karim', 'Somaca', 'Iskenderun', 'Emirates', 'Jounieh', 'Mashreq', 'Sharifa', 'Company', 'Rashid', 'Al kaabi', 'Mahmud', 'Sawamirah', 'Al-Batin', 'Hilal', 'Idris', 'al-Hayat', 'Nahid', 'Qom', 'Zarina', 'Al-Bilad', 'Al-Ittihad', 'Adnan', 'Hanaa', 'Ferrimaroc', 'Naji', 'Halima', 'Atta', 'Ridha', 'Khorramabad', 'Kairo', 'Souqalmal', 'Ashour', 'Maryam', 'Hayat', 'Ghulam', 'Harun', 'Ul’Jadid', 'Bahçelievler', 'GEMS', 'El azazma', 'Yonas', 'Djezzy', 'Razak', 'ez-Zor', 'Altibbi', 'Al-Arab', 'Adwya', 'Fuad', 'Randa', 'Khoy', 'Asif', 'Zaxo', 'One', 'Nusrat', 'Salih', \"Ha'il\", 'Starworld', 'JoSat', 'Zahida', 'Hammadi', 'PubliTools', 'Naqadeh', 'Samina', 'Ilam', 'Arabia', 'Siwarayn', 'Usman', 'Jalal', 'Yallacompare', 'Naziha', 'Faleh', 'Saida', 'Syriatel', 'Al-Massira', 'Ihab', 'Hawacom', 'Zarqa', 'Arzu', 'Anas', 'AvidBeam', 'Asyut', 'Sultangazi', 'Moussa', 'Ramzi', 'Shara', 'Ashmun', 'Leila', 'Neyshabur', 'Fadila', 'e&', 'Juma', 'Mardin', 'Ath', 'Arshad', 'Firas', 'Bibi', 'Sahraby', 'Hasib', 'Muhamad', 'ONTV', 'Elbenderi', 'Ahlat', 'Seyed', 'Hazem', 'Al-Mustaqbal', 'Sawaida', 'Hakima', 'Midyat', 'Naftal', 'Sulaiman', 'Yasmine', 'Najran', 'Khobar', 'Abha', 'Yasmin', 'Marsteller', 'Ordu', 'Salihli', 'QEWC', 'Dogonbadan', 'Okaz', 'Amna', 'Tarsus', 'Tishreen', 'Khan', 'Hamad', 'Wikaya', 'Souaha', 'Al-Horria', 'Al-Akhdar', 'Ismael', 'Bünyamin', 'Jawan', 'Wasla', 'Saliha', 'Ayman', 'Kermanshah', 'Alshaya', 'El natour', 'Adil', 'Jarallah', 'News', 'Akram', 'Saleh', 'Amira', 'Karaman', 'Siwar', 'Tunisavia', 'Yüksekova', 'Zuhra', 'Najma', 'Üsküdarr', 'Cevital', 'Ramla', 'Adiyaman', 'Munira', 'Bader', 'Aumet', 'Al sarhan', 'Khomeyni', 'Libyana', 'Fouad', 'Waseem', 'Comarit', 'Al-Mashriq', 'Soraya', 'Aramco', 'Nadeem', 'al-Jamahiriyah', 'alrajhi', 'Salam', 'Taghrid', 'Biougnach', 'Sonasid', 'Maltepe', 'Nazmi', 'Al fayoumi', 'Virtuzone', 'Ihsan', 'Lamsa', 'DenizBank', 'Phosphate', 'Hamdan', 'Marjane', 'Sumaya', 'Kord', 'Shahr-e', 'Sari', 'Süleyman', 'Iman', 'Rana', 'Borazjan', 'Dikirnis', 'Birjand', 'Cemal', 'Hasina', 'Anisa', 'LDC', 'Unifonic', 'ANB', 'Abdi', 'Matroud', 'Sabry', 'Abdulaziz', 'Careem', 'Layla', 'Bassam', 'Akl', 'Dawood', 'Deeb', 'beIN', 'Rasht', 'Qaym', 'Faris', 'Bashir', 'Al-Wehda', 'Laraki', 'Jamil', 'Adhra', 'Hisham', 'Ağrı', 'Rabih', 'Qarchak', 'Qasim', 'Tarik', 'Najafabad', 'Wassim', 'Ajmal', 'Houda', 'Maha', 'Kvindenavne', 'Najat', 'Alwasat', 'Ziba', 'Quchan', 'Taj', 'Daily', 'Langarud', 'Al huimel', 'Mukalla', 'Buraydah', 'Aldhilaymi', 'Yusef', 'Jawad', 'ALAHLI', 'Omer', 'Bayane', 'Mondair', 'Tokat', 'Latakia', 'Oilibya', 'Malek', 'Daraty', 'Tasnim', 'Bimo', 'Ahlibank', 'Musa', 'Siirt', 'Chefaa', 'BiscoMisr', 'Digital', 'Sayed', 'Saeed', 'Russeifa', 'Abjjad', 'Deir', 'Ramazan', 'Munuf', 'Toukh', 'Haidar', 'Mir', 'Sehmoudine', 'Ash', 'Bin', 'Mauritel', 'ibTECHar', 'Wisam', 'Zain', 'Sabri', 'Sirjan', 'Cerebras', 'Fatiha', 'Thawrah', 'Albyati', 'Jumeirah', 'Nasser', 'Saad', 'Al olaimat', 'Murtaza', 'Yousif', 'Miandoab', 'Investments', 'Cima', 'Shakila', 'Samsun', 'Antalya', 'Akhmim', 'Younes', 'Damaskus', 'Irfan', 'al-Fajr', \"A'zaz\", 'Yusuf', 'al-Arabi', 'Jamjamal', 'Melih', 'Ereğli', 'Yanbu', 'solutions', 'Ba Butayn', 'Sawaheel', 'Nilesat', 'Siham', 'Gaziantep', 'Salalah', 'Ooredoo', 'Nuri', 'Umair', 'Maysa', 'Fahad', 'Al naimi', 'Burhan', 'Mersa', 'Maroc', 'Isam', 'Sabah', 'DMC', 'Al-Yawm', 'Waqar', 'Batman', 'Telecom', 'Albawaly', 'Al', 'Sela', 'Disuq', 'Rahim', 'Muş', 'al-Maghribia', 'Liban', 'Ünye', 'Saman', 'Chandran', 'Ibb', 'Sinah', 'Lubna', 'Sami', 'Ramadi', 'Nur', 'Elaiouaikil', 'Feras', 'Jaafar', 'Silifke', 'Faqus', 'Mohamed aly', 'Dhamar', 'Tamer', 'Maher', 'Nadec', 'Shahnaz', 'Karabük', 'Banagas', 'Adam', 'Kadirli', 'Hurghada', 'Nabd', 'Alrifai', 'Amanat', 'Al-Nahar', 'Inagrab', 'Zakia', 'Al-Kalima', 'Suleiman', 'Nasr', 'El sherif', 'Başakşehir', 'Restaurants', 'Glass', 'Barakat', 'Shahin', 'K24', 'Babol', 'Jet4you', 'Eskisehir', 'Assadissa', 'Shams', 'Holdings', 'Salamiyah', 'Patchi', 'Nariman', 'Zaid', 'ONCF', 'Rayyan', 'Arabot', 'BulkWhiz', 'Nehmeh', 'Brahim', 'Malak', 'Zakariya', 'Jamilla', 'Bayan', 'al-Jarida', 'Mostapha', 'Østjerusalem', 'Jordan', 'Kamila', 'al-Jadid', 'Junes', 'Abou Hechich', 'Manama', 'Zeinab', 'Al awamer', 'Aniqa', 'Sadik', 'Kulayb', 'Salwa', 'Mahamed', 'Du', 'Rachid', 'Gul', 'Nada', 'Tyre', 'Trabzon', 'Lulu', 'al-Alam', 'Varamin', 'Zeytinburnu', 'Mushtaq', 'Albastji', 'Fatih', 'Gaza', 'Matruh', 'Afriquia', 'Huda', 'Najla', 'Arwa', 'Alsayed', 'Housh', 'Nadia', 'Kuşadası', 'Fatima', 'El ghany', 'As', 'Khamis', 'Agility', 'Ma’aden', 'Atef', 'Kahramaa', 'Hanadi', 'Aster', 'Power', 'Ar', 'Bayanat', 'Mina', 'Roy', 'Ad', 'Nouakchott', 'Fayez', 'Hotels', 'Muratpasa', 'Nabila', 'Balad', 'G42', 'Jassim', 'Karam', 'Hafar', 'Zghir', 'Sahlah', 'Malayer', 'BMMI', 'Ajil', 'May', 'Aldhibayti', 'Habiba', 'Osama', 'Ba Baiyr', 'Hamsa', 'Abid', 'Kassem', 'Erciş', 'Noman', 'Xenel', 'Khaled', 'Salima', 'Fadia', 'Tariq', 'Emaar', 'Abbas', 'Saleem', 'Zefta', 'Patnos', 'Gulf', 'Shahr', 'Yadav', 'Tunisna', 'Bushra', 'Sawahiry', 'Sonalgaz', 'Ala', 'Malik', 'al-Furat', '360VUZ', 'Jasmin', 'Sidra', 'Solutions', 'Rukban', 'HalalaH', 'Al-Muhaidib', 'Anwar', 'Kharabeesh', 'Aiguebelle', 'SOMED', 'Diwaniyah', 'Kitea', 'Samia', 'Chalus', 'Kutahya', 'Mouna', 'Alaizayri', 'Semnan', 'Darab', 'Aldar', 'Asima', 'Gorgan', 'Islamic', 'Afyonkarahisar', 'al-Muslimah', 'Yakub', 'Ümraniye', 'Lucidya', 'Al-Anbaa', 'Omdurman', 'El', 'Kezad', 'Rize', 'Rizwan', 'Alvand', 'Mazzika', 'Akbarabad', 'Abdel rahman', 'Ziad', 'Islam', 'Mounira', 'Damanhur', 'Nemer', 'Mohamed', 'Piranshahr', 'Bishah', 'Saidal', 'Sahlali', 'Albawaina', 'Sa', 'Noor', 'Sajjad', 'Suhayl', 'Hasna', 'Alairaysiah', 'Behbahan', 'Said', 'Akhbar', 'Mo’men', 'Rayan', 'Mubadala', 'Samra', 'Vermeg', 'Dabbas', 'Malaeb', 'Asad', 'Ashabiba', 'Samarra', 'Junaid', 'Ayoub', 'Fertiglobe', 'Bitar', 'Sahi', '3ayez', 'Jihad', 'Hafsa', 'Al saadi', 'Tarjama', 'Mathaqi', 'SNRT', 'Zonguldak', 'Farah', 'DM', 'Hinna', 'Healthcare', 'Şişli', 'Afrah', 'Khomeyn', 'Aligudarz', 'al-Jadida', 'Selim', 'Jablah', 'SAMI', 'Nazih’', 'Koutoubia', 'Al-Ouruba', 'Al rashedi', 'Ramadan', 'Kazerun', 'Corlu', 'Samad', 'Elazig', 'Abdul jalil', 'Hussam', 'Ceyhan', 'Shawarmer', 'Abed', 'KIPCO', 'al-Balad', 'Erzurum', 'Party', 'Asia', 'Hasan', 'Doğubayazıt', 'Abu Jabir', 'Wail', 'Hana', 'Mines', 'Hena', 'Omar', 'Altimayhi', 'Aleppo', 'Front', 'Burdur', 'ViaVii', 'Kashif', 'Talkha', 'Abida', 'Ben', 'Alaysuli', 'Swvl', 'Rahima', '2M', 'Saudi', 'Deyaar', 'Daria', 'Intisar', 'Shiraz', 'Bağcılar', 'Mahdi', 'Robat', 'al-Yaoume', 'Malaika', 'Mostafa', 'Monoprix', 'Turgutlu', 'Naja', 'Lama', 'Khorramshahr', 'Filasteen', 'Dussur', 'Nazim', 'Rezayat', 'Ikram', 'Shoaib', 'Zabol', 'Tabriz', 'Muscat', 'ACWA', 'Hawaï', 'Aliya', 'Abdel sada', 'Beirut', 'Mikail', 'Naia', 'Rafiq', 'Ayuub', 'Zaki', 'Nagham', 'Morad', 'Elves', 'Hamza', 'Orumiyeh', 'Zahedan', 'Massaya', 'Zubayr', 'Wafa', 'Jasmine', 'Wael', 'Saham', 'Sharjah', 'Lana', 'Wanasah', 'Mahmood.', 'Qalyub', 'Jadoua', 'Qurayyat', 'Madaba', 'Dubai', 'Az', 'QNB', 'Siwarah', 'Samreen', 'Shafa', 'Iran', 'al-Zahf', 'bank', 'Konya', 'Al-Intiqad', 'Al-Waie', 'Altiwayliah', 'Zagazig', 'Mosul', 'Al issa', 'Aminah', 'Hamadan', 'MarsaMaroc', 'Mubarak', 'Wafaa', 'Ali', 'Kavus', 'Jabalya', 'Hamouda', 'Mahfouz', 'Madiha', 'Shahrud', 'Solfeh', 'Shihan', 'Kesmoulkerim', 'Dar', 'Abdel', 'Bhatia', 'Ehsan', 'Walid', 'Odeh', 'Nouvelair', 'Athaqafia', 'Bahri', 'Arasco', 'Noon', 'Qasimo Alfadil', 'Mirza', 'Almarai'}\n"
     ]
    }
   ],
   "source": [
    "print(used_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "ce5ad0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for sent in ME_dev: \n",
    "#    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "f48b4937",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for sent in ME_test: \n",
    "#    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "81a594f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as tsv files\n",
    "write_tsv_file(ME_dev, \"../data/me_data/middle_eastern_dev.tsv\")\n",
    "write_tsv_file(ME_test, \"../data/me_data/middle_eastern_test.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "287171b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_iob2_file(ME_test, path=\"../data/me_data/middle_eastern_test.iob2\", gold=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
