{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from ME_BPER import ME_BPER\n",
    "from ME_IPER import extract_last_names\n",
    "from ME_LOC import add_location\n",
    "from ME_ORG import add_organisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading label data from a given column\n",
    "# this is the readNlu function from the provided span_f1 file\n",
    "# minor modifications were made to make it usable with our data. \n",
    "def readNlu(path, target_column = 1): # default to index 1 (thats where DaN+ labels are)\n",
    "    '''\n",
    "    This function reads labeled annotations from a CoNLL-like file.\n",
    "\n",
    "    It parses a file where each line typically represents a single token and its annotations,\n",
    "    separated by tabs. Empty lines denote sentence boundaries. It extracts labels from a specified column\n",
    "    (by default, column index 1), collecting them as a list of label sequences, one per sentence.\n",
    "\n",
    "    Parameters:\n",
    "        path (str): Path to the input file.\n",
    "        target_column (int, optional): Index of the column to extract labels from. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        List[List[str]]: A list where each element is a list of labels (strings) corresponding\n",
    "                         to tokens in a sentence.\n",
    "    '''\n",
    "\n",
    "    annotations = []    # list for storing all the label sequences (one per sentence)\n",
    "    cur_annotation = [] # temp list for labels of the current sentence\n",
    "\n",
    "    # reading through the file line by line\n",
    "    for line in open(path, encoding='utf-8'):\n",
    "        line = line.strip()                     # remove leading/trailing whitespaces\n",
    "\n",
    "        # empty lines denotes end of sentence\n",
    "        if line == '':\n",
    "            annotations.append(cur_annotation)  # add current annotations to annotations list\n",
    "            cur_annotation = []                 # reset for the next sentence\n",
    "        \n",
    "        # skipping comments (start with \"#\" and no tokens columns)\n",
    "        elif line[0] == '#' and len(line.split('\\t')) == 1:\n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            # extract the label from the specified column and add to current sentence\n",
    "            cur_annotation.append(line.split('\\t')[target_column])\n",
    "\n",
    "    return annotations\n",
    "\n",
    "\n",
    "# mapping funciton \n",
    "def mapping(path):\n",
    "    '''\n",
    "    This function generates mappings between labels and their corresponding integer IDs from a labeled dataset.\n",
    "\n",
    "    It reads annotations from a CoNLL-like file using the `readNlu` function,\n",
    "    filters out labels containing substrings like \"part\" or \"deriv\" (case-insensitive),\n",
    "    and creates a bidirectional mapping between the remaining unique labels and integer IDs.\n",
    "\n",
    "    Parameters:\n",
    "        path (str): Path to the labeled data file.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Dict[str, int], Dict[int, str]]:\n",
    "            - label2id: A dictionary mapping each label to a unique integer ID.\n",
    "            - id2label: A reverse dictionary mapping each integer ID back to its label.\n",
    "    '''\n",
    "\n",
    "    # get the data labels\n",
    "    data_labels = readNlu(path) \n",
    "\n",
    "    # create empty set to store unique labels\n",
    "    label_set = set()\n",
    "\n",
    "    for labels in data_labels:\n",
    "        #  filter out any labels that contain 'part' or 'deriv' (case-insensitive)\n",
    "        filtered = [label for label in labels if 'part' not in label.lower() and 'deriv' not in label.lower()]\n",
    "        label_set.update(filtered)\n",
    "\n",
    "    # count of unique filtered labels\n",
    "    num_labels = len(label_set)\n",
    "\n",
    "    # create a dictionary mapping each label to a unique integer ID\n",
    "    label2id = {label: id for id, label in enumerate(label_set)}\n",
    "\n",
    "    # create a dictionary mapping each unique integer ID to a label\n",
    "    id2label = {id: label for label, id in label2id.items()}\n",
    "\n",
    "    return label2id, id2label\n",
    "\n",
    "\n",
    "# load data function\n",
    "# heavily inspired by the solution from assignment 5\n",
    "def read_tsv_file(path, label2id):\n",
    "    '''\n",
    "    This function reads a TSV file containing tokens and NER labels and converts it into structured data.\n",
    "    It collects the tokens, their original labels, and their corresponding integer IDs (based on the provided `label2id` mapping) for each sentence.\n",
    "    Sentences are separated by empty lines. \n",
    "\n",
    "    Each non-empty line in the file is expected to have at least two tab-separated columns:\n",
    "    - The first column is the token.\n",
    "    - The second column is the corresponding NER label.\n",
    "\n",
    "    Parameters:\n",
    "        path (str): Path to the TSV file to read.\n",
    "        label2id (dict): A dictionary mapping NER label strings to their corresponding integer IDs.\n",
    "\n",
    "    Returns:\n",
    "        List[dict]: A list of dictionaries, one per sentence, with keys:\n",
    "            - 'tokens': list of tokens.\n",
    "            - 'ner_tags': list of original NER label strings.\n",
    "            - 'tag_ids': list of integer tag IDs corresponding to the NER labels.\n",
    "    '''\n",
    "\n",
    "    data = []               # final list to hold all sentences as dictionaries\n",
    "    current_words = []      # tokens for the current sentence\n",
    "    current_tags = []       # NER tags for the current sentence\n",
    "    current_tag_ids = []    # corresponding tag IDs for the current sentence\n",
    "\n",
    "    for line in open(path, encoding='utf-8'):\n",
    "        line = line.strip() # removes any leading and trailing whitespaces from the line\n",
    "\n",
    "        if line:\n",
    "            if line[0] == '#': \n",
    "                continue # skip comments\n",
    "\n",
    "            # splitting at 'tab', as the data is tab separated \n",
    "            tok = line.split('\\t')\n",
    "            \n",
    "            # extract the token (first column)\n",
    "            token = tok[0]\n",
    "\n",
    "            # check if the label is in the provided label2id dictionary\n",
    "            # if it's not, replace the label with 'O'\n",
    "            label = tok[1] if tok[1] in label2id else 'O'\n",
    "\n",
    "            current_words.append(token)\n",
    "            current_tags.append(label)\n",
    "            current_tag_ids.append(label2id[label])\n",
    "        \n",
    "        else: # skip empty lines\n",
    "            if current_words: # if current_words is not empty\n",
    "\n",
    "                # add entry to dict where tokens and ner_tags are keys and the values are lists\n",
    "                data.append({\"tokens\": current_words, \"ner_tags\": current_tags, \"tag_ids\": current_tag_ids})\n",
    "\n",
    "            # start over  \n",
    "            current_words = []\n",
    "            current_tags = []\n",
    "            current_tag_ids = []\n",
    "\n",
    "    # check for last one\n",
    "    if current_tags != []:\n",
    "        data.append({\"tokens\": current_words, \"ner_tags\": current_tags, \"tag_ids\": current_tag_ids})\n",
    "  \n",
    "    return data\n",
    "\n",
    "# extracting tokens to check for overlap in train, dev and test sets\n",
    "def extract_labeled_tokens(dataset, exclude_label = \"O\", include_label_pair=False):\n",
    "    '''\n",
    "    This function extracts tokens from a dataset that have a string label different from `exclude_label`.\n",
    "    Optionally, it can return the (token, label) pairs instead of just tokens.\n",
    "\n",
    "    Parameters:\n",
    "        dataset (List[dict]): The token-tagged dataset.\n",
    "        exclude_label (str): The label to ignore (default is 'O').\n",
    "        include_label_pair (bool): Whether to include the (token, label) pairs in the result (default is False).\n",
    "        \n",
    "    Returns:\n",
    "         Set[str] or Set[Tuple[str, str]]: \n",
    "            - A set of tokens with meaningful (non-O) labels if `include_label_pair` is False.\n",
    "            - A set of (token, label) pairs if `include_label_pair` is True.\n",
    "    '''\n",
    "\n",
    "    # create empty set to store the unique tokens\n",
    "    labeled_tokens = set()\n",
    "    \n",
    "    for sentence in dataset:\n",
    "        # iterate over each token and its corresponding tag ID\n",
    "        for token, label in zip(sentence[\"tokens\"], sentence[\"ner_tags\"]):\n",
    "            if label != exclude_label:                      # check if the tag is not the excluded one\n",
    "                if include_label_pair:\n",
    "                    labeled_tokens.add((token, label))      # add (token, label) pair if the flag is True\n",
    "                else:\n",
    "                    labeled_tokens.add(token)               # add just the token if the flag is False\n",
    "    \n",
    "    return labeled_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data_aug_sources/the-middle-east-cities.csv\", sep = \";\", skiprows = 1)\n",
    "unique_city_da = df[\"city_da\"].drop_duplicates()\n",
    "ME_LOC = [add_location(loc) for loc in unique_city_da]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data_aug_sources/middle_eastern_organisations.csv\", sep = \";\", skiprows = 1)\n",
    "unique_orgs = df[\"org\"].drop_duplicates()\n",
    "ME_ORG = [add_organisation(org) for org in unique_orgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "ME_IPER = extract_last_names(\"../data_aug_sources/middle_eastern_last_names.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_entity_strings(data, target_label_prefix):\n",
    "    \"\"\"\n",
    "    Collects labeled spans as strings from the dataset. Multi-token spans are joined with spaces.\n",
    "    \n",
    "    Args:\n",
    "        data (List[Dict]): Dataset containing 'tokens' and 'tags' for each sentence.\n",
    "        target_label_prefix (str): Label prefix to filter for (e.g., 'B-LOC', 'B-ORG').\n",
    "        \n",
    "    Returns:\n",
    "        Set[str]: A set of labeled token strings (e.g., {'Beirut', 'Al Mawsil al Jadidah'})\n",
    "    \"\"\"\n",
    "    grouped_strings = set()\n",
    "\n",
    "    for item in data:\n",
    "        tokens = item['tokens']\n",
    "        tags = item['ner_tags']\n",
    "\n",
    "        i = 0\n",
    "        while i < len(tokens):\n",
    "            tag = tags[i]\n",
    "\n",
    "            if tag.startswith(target_label_prefix):\n",
    "                span_tokens = [tokens[i]]\n",
    "                i += 1\n",
    "                while i < len(tokens) and tags[i].startswith('I'):\n",
    "                    span_tokens.append(tokens[i])\n",
    "                    i += 1\n",
    "\n",
    "                # Join tokens into a single string and add to the set\n",
    "                entity_string = ' '.join(span_tokens)\n",
    "                grouped_strings.add(entity_string)\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "    return grouped_strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Kafr ad Dawwar', 'Bawshar', 'Kayseri', 'Turgutlu', 'Al Fujayrah', 'Bagdad', 'Damietta', 'Najafabad', 'Amran', 'Van', 'Dar Kulayb', 'Sari', 'Iğdır', 'Kafr ash Shaykh', 'Dahuk', 'Borujerd', 'Bolu', 'Zabol', 'Abhar', 'Al Hufuf', 'Jamjamal', 'Bani Suwayf', 'Ağrı', 'Bingöl', 'Atasehir', 'Bahrain', 'Østjerusalem', 'Qalyub', 'Ilam', 'Ödemiş', 'Shirvan', 'Manisa', 'Kuwait', 'Gaziantep', 'Abadan', 'Madaba', 'Silifke', 'Tokat', 'Dehdasht', 'Tarut', 'Kashmar', 'Soma', 'Nizwa', 'Zeytinburnu', 'Qurayyat', 'Nazarabad', 'Manavgat', 'Sorgun', 'Kastamonu', 'Al Ain', 'Çerkezköy', 'Diyarbakir', 'Behshahr', 'Isfahan', 'Nusaybin', 'Silopi', 'Firuzabad', 'Abu Dhabi', 'Giresun', 'Sanandaj', 'Şişli', 'Kazerun', 'Ahar', 'Toukh', 'Piranshahr', 'Khorramabad', 'Irak', 'Zaxo', 'New Cairo', 'Ismailia', 'Varamin', 'Ardabil', 'Al Basrah al Qadimah', 'Borazjan', 'Buraydah', 'Al Bahah', 'Kufa', 'Trabzon', 'Seeb', 'Nurabad', 'Mersa Matruh', 'Al Mansurah', 'Ereğli', 'Fuwwah', 'Kafr az Zayyat', 'As Suwayq', 'Ordu', 'Ayvalık', 'Qina', 'Darayya', 'Iran', 'Khobar', 'Tyre', 'Masjed Soleyman', 'Al-Hudaydah', 'Amol', 'Turhal', 'Burdur', 'Mashhad', 'Çorum', 'Disuq', 'Orumiyeh', 'Al Fallujah', 'Robat Karim', 'Yazd', 'Awsim', 'Adapazari', 'Shahr-e Kord', 'Samsun', 'Kadirli', 'Damaskus', 'Ibri', 'Kahriz', 'Aswan', 'Kirikkale', 'Parsabad', 'Rukban', 'Alvand', 'Kahramanmaraş', 'Rosetta', 'Samarra', 'Daraa', 'Erzincan', 'As Salamiyah', 'Wadi as Sir', 'Erciş', 'Al Kharijah', 'Çanakkale', 'Qazvin', 'Muş', 'Forenede Arabiske Emirater', 'Kuşadası', 'Shiraz', 'Azadshahr', 'Isparta', 'Banha', 'Mahabad', 'As Safirah', 'Saham', 'Tabriz', 'Sabzevar', 'Khalis', 'Çubuk', 'Ahvaz', 'Akhmim', 'Rafah', 'Bandırma', 'Üsküdarr', 'Shibin al Kawm', 'Bush', 'Taiz', 'Baqubah', 'Ash Shafa', 'Babol', 'Sultanbeyli', 'Al-Hasakah', 'Luxor', 'Batman', 'As-Salt', 'Al Kharj', 'Najaf', 'Sultanah', 'Sayhat', 'Housh Eissa', 'Sohar', 'Sharjah', 'Aydin', 'Mallawi', 'Ramadi', 'Rustaq', 'Viranşehir', 'Yüksekova', 'Shahrud', 'Ahlat', 'Gebze', 'Arar', 'Hamadan', 'Dogonbadan', 'Izmir', 'Lüleburgaz', 'Kızıltepe', 'Kuhdasht', 'Saveh', 'Homs', 'Quchan', 'Istanbul', 'Bahçelievler', 'Tarsus', 'Rafsanjan', 'Söke', 'Syrien', 'Al Matariyah', 'Khan Yunis', 'Zahle', 'Mukalla', 'Al Buraymi', 'Basra', 'Dubai', 'Dammam', 'Bandar-e Anzali', 'Al Farwaniyah', 'Jordan', 'Qorveh', 'Konya', 'Nazilli', 'Marand', 'Osmaniye', 'Mustafakemalpaşa', 'Shushtar', 'Nizip', 'Ar Rass', 'Ras Beirut', 'Zagazig', 'Bishah', 'Arak', 'Akşehir', \"Ha'il\", 'Idlib', 'Khoy', 'Takestan', 'Al Hillah', 'Büyükçekmece', 'Nevşehir', 'Aden', 'Khamis Mushait', 'Mekka', 'Manbij', 'Al Fahahil', 'Manama', 'Mosul', 'Edfu', 'Al Qusiyah', 'Al Mubarraz', 'Al Fayyum', 'Sabah as Salim', 'Belek', 'Al Fashn', 'Tripoli', 'Munuf', 'Faqus', 'Batikent', 'Ar Ramtha', 'Minab', 'Khomeyn', 'Samalut', 'Anzal-e Jonubi', 'Jabalya', 'Ankara', 'Balikesir', 'Hakkari', 'Shahre Jadide Andisheh', 'Aligudarz', 'Zarqa', 'Damanhur', 'Afyonkarahisar', 'Aksaray', 'Mardin', 'Siirt', 'Antakya', 'Merkezefendi', 'Başakşehir', 'Erbil', 'Amman', 'Doha', 'Alexandria', 'Elbistan', 'Damghan', 'Midyat', 'Sohag', 'Jirja', 'Chalus', 'Abnub', 'Bonab', 'Hurghada', 'As Salimiyah', 'Tabuk', 'Semnan', 'Irbid', 'Halwan', 'Kutahya', 'Yasuj', 'Zefta', 'Naqadeh', 'Manfalut', 'Mersin', 'Ar Rifa', 'Rasht', 'Abu Kabir', 'Al Hayy', 'Bursa', 'Nasiriyah', 'Çankaya', 'Miandoab', 'Bukan', 'Saqqez', 'Erzurum', 'Al-Arish', 'Baneh', 'Al Manzalah', 'Al Khankah', 'Marivan', 'Karabağlar', 'Ibb', 'Gaza', 'Edirne', 'Beirut', 'Bam', 'Az Zubayr', 'Sinah', \"A'zaz\", 'Qom', 'Sanaá', \"Ta'if\", 'Tahta', 'Saudi Arabien', 'Rize', 'Ümraniye', 'Tyrkiet', 'Port Said', 'Şanlıurfa', 'Teheran', 'Umm Qasr', 'Libanon', 'Dhahran', 'Tartus', 'Salihli', 'Oman', 'Langarud', 'Eskisehir', 'Asyut', 'Maltepe', 'İnegöl', \"Al 'Amarah\", 'Ash Shatrah', 'Kahta', 'Antalya', 'Ajman', 'Isna', 'Al Muharraq', 'Ath Thawrah', 'Sur', 'Ünye', 'Tekirdağ', 'Salmas', 'Russeifa', 'Niğde', 'Uşak', 'Muscat', 'Malatya', 'Bushehr', 'Ras al-Khaimah', 'Hamah', 'Al Qatif', 'Ashmun', 'Aleppo', 'Jidda', 'Jablah', 'Qarchak', 'Abu Ghurayb', 'Esenler', 'Akhisar', 'Neyshabur', 'Ajlun', 'Hafar Al-Batin', 'Sidon', 'Sulaymaniyah', 'Silvan', 'Karbala', 'Muratpasa', 'Doğubayazıt', 'Kermanshah', 'Gorgan', 'Abu Tij', 'Akbarabad', 'Kozan', 'Al Faw', 'Jounieh', 'Sakakah', 'Polatlı', 'Nablus', 'Riyadh', 'Yalova', 'Gemlik', 'Ardeşen', 'Al Jammaliyah', 'Al Bab', 'Darab', 'Al Harithah', 'Fatsa', 'Barka', 'Giza', 'Al Mawsil al Jadidah', 'Talkha', 'Bilbeis', 'Khomeyni Shahr', 'Sancaktepe', 'Aqaba', 'Medina', 'Tatvan', 'Malayer', 'Al Mahallah al Kubra', 'Sayyan', 'Ar Rayyan', 'Gonbad-e Kavus', 'Khanjarah', 'Egypten', 'Ceyhan', 'Nabatiye et Tahta', 'Dayrut', 'Abha', 'Al Minya', 'Patnos', 'Siverek', 'Al Ahmadi', 'Fasa', 'Behbahan', 'Khash', 'Torbat-e Heydariyeh', 'Sivas', 'Dikirnis', 'Hawalli', 'Kairo', 'Cizre', 'As Samawah', 'Kars', 'Iranshahr', 'Bilqas', 'Izmit', 'Kerman', 'Latakia', 'Zanjan', 'Adana', 'Ad Diwaniyah', 'Kilis', 'Idku', 'Karaman', 'Deir ez-Zor', 'Adiyaman', 'Alanya', 'Karabük', 'Kirkuk', 'Yanbu', 'Khorramshahr', 'Yozgat', 'Hebron', 'Zahedan', 'Arnavutköy', 'Jizan', 'Al Hawamidiyah', 'Denizli', 'Esenyurt', 'Dhamar', 'Bandar Abbas', 'Birjand', 'Bismil', 'Al Jubayl', 'Elazig', 'Salalah', 'Bojnurd', 'Nahavand', 'Beylikduezue', 'Zonguldak', 'Bafra', 'Palæstina', 'Douma', 'Corlu', 'Ar Raqqah', 'Suez', 'Körfez', 'Bağcılar', 'Iskenderun', 'Karaj', 'Habbouch', 'Sirjan', 'Sultangazi', 'Al Kut', 'Najran', 'Tanda', 'Herzliya', 'Kırşehir'}\n",
      "480\n",
      "481\n",
      "\n",
      "\n",
      "{'Al Tayer Group', 'Sahara International Petrochemical Company', 'Dubai Airports Company', 'Dubai Electricity and Water Authority', 'Cerebras', 'Assadissa', 'SOMED', 'Balad Party', 'Alwasat', 'QNB Group', 'Saudia', 'El Hiwar El Tounousi', 'Al Yah Satellite Communications', 'Commercial International Bank', 'Saudi Awwal Bank', 'al-Jamahiriyah', 'The Ghassan Aboud Group', 'Al Amal', 'Bakdash', 'Oilibya', 'Kahramaa', 'ACWA Power', 'Al Eqtisadiah', 'Maroc Telecom', 'ADES Holding', 'Marjane', 'Somaca', 'Empower', '3ayez', 'The International Islamic Charitable Organization', 'Amanat Holdings', 'e&', 'Unifonic', 'Altibbi', 'Nouvelair', 'Zain KSA', 'Tunisna', 'Filasteen al-Muslimah', 'al-Fajr al-Jadid', 'arab national bank', 'Sela', 'Solfeh', 'Sarwa', 'Attajdid', 'Monoprix', 'Libyana', 'SNRT', 'QNB ALAHLI', 'BCP Group', 'Arab Democratic Nasserist Party', 'Ras Al Khaimah Economic Zone', 'Kayhan Al Arabi', 'Al-Tijari', 'Commercial Bank of Dubai', 'al-Hayat al-Jadida', 'National Bank of Fujairah', 'Evertek', 'solutions by stc', 'Al Kuwaitiya', 'Al Sharq', 'Kharabeesh', 'Marina Home', 'Nasr', 'Al Yaum', 'One', 'Al Ahli Bank of Kuwait', 'JoSat', 'TGCC', 'Al-Mustaqbal', 'Ooredoo Group', 'Al-Thawra', 'Hawacom', 'Argaam', 'Riyad Bank', 'The Khalifa Foundation', 'Kuwait Projects Company', 'al-Watan', 'National Covenant Party', 'Emirates Airline', 'Wikaya', 'Tishreen', 'Al Manar', 'Ooredoo', 'Popular Movement in Iraq', 'Al-Massira', 'Al Aoula', 'Dabchy', 'Electroplanet', 'DMC', 'International Holding Company', 'Swvl', 'Khaleej Times', 'Alinma Bank', 'Al Anbaa', 'Abu Dhabi Islamic Bank', 'Emirates Integrated Telecommunications Company', 'Nilesat', 'Elm', 'Bank AlJazira', 'Henkel GCC', 'al-Bayan', 'AD Ports Group', 'Nadec', 'Ferrimaroc', 'Al Liwaa', 'RASCO', 'Al-Muhaidib', 'stc Group', 'Marafiq', 'NBN', 'Athaqafia', 'Istiqlal Party', 'Baladna', 'Dussur', 'Al-Kalima', 'DEWA', 'Boubyan Bank', 'Djezzy', 'Emirates NBD', 'DenizBank', 'El Mehwar', 'OSN', 'Al Ayam', 'Emirates Islamic', 'Fetchr', 'PureHealth Holding', 'Islamic Relief Worldwide', 'Assabeel', 'The Jordan River Foundation', 'Al Jamahir', 'QEWC', 'Noon', 'Al-Horria', 'Dubai Investments', 'Roya TV', 'Jawan', 'Alshaya', 'Akdital', 'Zaytouna TV', 'Gulfsat', 'Bayane al-Yaoume', 'Jumeirah Hotels', 'Wallyscar', 'Hawaï', 'Arabot', 'Asdaa Burson Marsteller', 'Gulf Bank', 'Al Rayaam', 'SGTM', 'Daily Sabah', 'Jamalon', 'Muscat Stock Exchange', 'SNVI', 'BiscoMisr', 'PubliTools', 'First Abu Dhabi Bank', 'Okaz', 'The Palestinian Medical Relief Society', 'al-Furat', 'Mrsool', 'MBC', 'Aluminium Bahrain', 'Aramco', 'Tunisavia', 'Afriquia', 'Deyaar', 'Saudi Investment Bank', 'ibTECHar Digital Solutions', 'Jumeirah Group', 'Aïcha', 'Comarit', 'Shorooq Partners', 'Emsteel', 'al-Zahf Al-Akhdar', 'Air Arabia', 'Bank Of Africa', 'Virtuzone', 'Savola Group', 'Laraki', 'Massaya', 'Mo’men', 'Arab Fund for Economic and Social Development', 'Batelco', 'Al Watan', 'Du', '218TV', 'Al-Intiqad', 'CBC', 'Dnata', 'Borouge', 'Careem', 'Siger', 'beIN SPORTS', 'Almarai', 'Arab Bank', 'Doha Bank', 'Malaeb', 'Managem', 'Al Anbat', 'Egyptalum', 'Naftal', 'Gulf News', 'Al Raya', 'Al-Ahram', 'G42', 'Dukhan Bank', 'Kitea', 'Al-Mamlaka TV', 'Kingdom Holding Company', 'Saudi National Bank', 'Al Shorouk', 'Mubadala', 'Bank Muscat', 'BMCI', 'NMDC Group', 'Syriatel', 'ADCB Group', 'Epilert', 'Arasco', 'Qatar International Islamic Bank', 'Al Massar', 'Amal Glass', 'Al-Kifah al-Arabi', 'GEMS Education', 'Aumet', 'Yallacompare', 'Al-Nahar', 'Kharafi Group', 'Kuwait Oil Company', 'Cevital', 'Qatar Charity', 'Ad-Dustour', '360VUZ', 'Emaar Properties', 'Omantel', 'HalalaH', 'Sopriam', 'OTV', 'Torath', 'LDC', 'Ahlibank', 'Saudi Electricity Company', 'Al Rayyan', 'Naseej', 'Télé Liban', 'Arab Socialist Union Party of Syria', 'Mauritel', 'Saudi Arabian Mining Company', 'eSpace', 'Ashabiba', 'Echorouk Group', 'Emirates Red Crescent', 'Zain Group', 'Tamatem', 'Flynas', 'Al-Ouruba', 'Lamsa', 'Al-Ittihad', 'Agility', 'Polisario Front', 'Starworld', 'Qatar Fuel', 'Qatar Islamic Bank', 'PSLab', 'Industries Qatar', 'The Noor Dubai Foundation', 'Kuwait Finance House', 'National Bank of Kuwait', 'EgyptAir', 'Etihad Etisalat Company', 'ZenHR Solutions', 'Sonasid', 'National Bank of Ras Al Khaimah', 'Iqraa', 'Banagas', 'Sawani', 'K24', 'al-Alam', 'Elves', 'Burgan Bank Group', 'TAQA Group', 'NBB Group', 'Banque Saudi Fransi', 'alrajhi bank', 'Jet4you', 'Al-Wehda', 'Shamsina', 'Adaraweesh', 'al-Jarida al-Maghribia', 'Apparel Group', 'Nareva', 'Dr. Sulaiman Al Habib Medical Services Group', 'Alpha Dhabi Holding', 'LuLu Group', 'Souqalmal', 'Omdurman', 'RasGas', 'Palestinian Liberation Front', 'SABIC Agri-Nutrients Company', 'Etisalat', 'Sonatrach', 'The UAE’s Zayed Giving Initiative', 'Ma’aden', 'Thumbay Group', 'ADNOC Gas', 'Bank Albilad', 'Bank ABC', 'Bahrain Islamic Bank', 'Asmidal', 'Fajr Capital', 'Rezayat', 'KTV2', 'Saudi Aramco Base Oil Company', 'Shihan', 'Aldar Properties', 'Cima', 'Ajeer', 'ViaVii', 'Shawarmer', 'Cinescape', 'Siera', 'Nabd', 'Al Mada', 'Al Karmil', 'Al Madina', 'Masraf Al Rayan', 'Akhbar Al Khaleej', 'Commercial Bank', 'Talabat', 'Al-Mashriq', 'Mekameleen TV', 'Fertiglobe', 'Mathaqi', 'Eco-Médias', 'MarsaMaroc', 'ADNOC', 'Attijariwafa bank group', 'BMMI', 'Wanasah', 'al-Qabas', 'Aiguebelle', 'The Arab Medical Union', 'Adwya', 'Al Quds Association', 'Lucidya', 'Investcorp', 'SAMI', 'Abjjad', 'Spinneys', \"Arab Socialist Ba'ath Party\", 'GIB Capital', 'Colorado', 'Bupa Arabia', 'Saidal', 'The Company for Cooperative Insurance', 'Tabbah', 'The Syrian American Medical Society', 'ArabiaWeather', 'El Heddaf', 'AL24 News', 'Bayanat', 'Derq', 'Vermeg', 'Al-Waie', 'National Shipping Company of Saudi Arabia', 'Kudu', '2M', 'Americana Restaurants', 'Mashreq', 'Wasla', 'Al-Ahd Ul’Jadid', 'Al-Bilad', 'AKKASA', 'Ad Diyar', 'Chefaa', 'Sharjah Islamic Bank', 'GoEjaza', 'Bimo', 'Dubai Islamic Bank', 'Danube Group', 'Xenel', 'Khartoum', 'Damac', 'BulkWhiz', 'Bahri', 'Al-Arab Al-Yawm', 'Daraty', 'Inwi', 'Asiacell', 'KIPCO', 'Emaar Development', 'Jordan Phosphate Mines Company', 'Al Rai', 'Inagrab', 'Mondair', 'Mazzika', 'Mobily', 'Biougnach', 'Alrifai', 'Al Jumhuriya', 'Akhbar Nouakchott', 'Nehmeh', 'Al Jazeera', 'Sonalgaz', 'Nagham', 'Arryadia', 'Tarjama', 'Echorouk', 'Koutoubia', 'ONTV', 'Kezad', 'Saudi Aramco', 'Patchi', 'Nakilat', 'Mawdoo3', 'al-Balad', 'ANB', 'AvidBeam', 'The Qatar Fund for Development', 'Qaym', 'Al-Anbaa', 'Aster DM Healthcare', 'Qatar Insurance Company', 'Mazazikh', 'Al Nabooda Automobiles', 'ONCF', 'Gulf Madhyamam'}\n",
      "427\n",
      "427\n"
     ]
    }
   ],
   "source": [
    "# overlap between train, dev, test and MENAPT NEs\n",
    "ME_LOC_tokens = collect_entity_strings(ME_LOC, target_label_prefix = \"B-LOC\")\n",
    "\n",
    "ME_ORG_tokens = collect_entity_strings(ME_ORG, target_label_prefix = \"B-ORG\")\n",
    "\n",
    "print(ME_LOC_tokens)\n",
    "print(len(ME_LOC_tokens))\n",
    "print(len(ME_LOC))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(ME_ORG_tokens)\n",
    "print(len(ME_ORG_tokens))\n",
    "print(len(ME_ORG))\n",
    "\n",
    "ME_BPER_tokens = set(ME_BPER)\n",
    "ME_IPER_tokens = set(ME_IPER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the data files\n",
    "path_train = \"../data/da_news_train.tsv\"\n",
    "path_dev = \"../data/da_news_dev.tsv\"\n",
    "path_test = \"../data/da_news_test.tsv\"\n",
    "\n",
    "# create mapping\n",
    "label2id, id2label = mapping(path_train)\n",
    "\n",
    "# read in the DaN+ data\n",
    "train_data = read_tsv_file(path_train, label2id)\n",
    "dev_data = read_tsv_file(path_dev, label2id)\n",
    "test_data = read_tsv_file(path_test, label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_entity_strings(data, exclude_label=\"O\"):\n",
    "    \"\"\"\n",
    "    Collects all labeled (non-\"O\") entity spans as strings from the dataset.\n",
    "    Multi-token spans are joined with spaces.\n",
    "\n",
    "    Args:\n",
    "        data (List[Dict]): Dataset with 'tokens' and 'tags' per sentence.\n",
    "        exclude_label (str): Label to ignore (default is 'O').\n",
    "\n",
    "    Returns:\n",
    "        Set[str]: Set of labeled entity strings (e.g., {'Beirut', 'Al Mawsil al Jadidah'})\n",
    "    \"\"\"\n",
    "    grouped_strings = set()\n",
    "\n",
    "    for item in data:\n",
    "        tokens = item['tokens']\n",
    "        tags = item['ner_tags']\n",
    "        i = 0\n",
    "        while i < len(tokens):\n",
    "            tag = tags[i]\n",
    "\n",
    "            if tag != exclude_label and tag.startswith('B-'):\n",
    "                span_tokens = [tokens[i]]\n",
    "                i += 1\n",
    "                # Collect I-XXX continuation tags\n",
    "                while i < len(tokens) and tags[i].startswith('I-'):\n",
    "                    span_tokens.append(tokens[i])\n",
    "                    i += 1\n",
    "\n",
    "                entity_string = ' '.join(span_tokens)\n",
    "                grouped_strings.add(entity_string)\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "    return grouped_strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = collect_all_entity_strings(train_data)\n",
    "dev_tokens = collect_all_entity_strings(dev_data)\n",
    "test_tokens = collect_all_entity_strings(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap loc train:  {'Erzincan', 'Luxor', 'Ankara', 'Kuwait', 'Irak', 'Abu Dhabi', 'Syrien', 'Bush'}\n",
      "overlap loc dev:  {'Bahrain', 'Oman'}\n",
      "overlap loc test:  {'Irak', 'Bagdad'}\n",
      "overlap org train:  {'CBC'}\n",
      "overlap org dev:  {'CBC'}\n",
      "overlap org test:  set()\n",
      "overlap BPER train:  {'Elias', 'Bassam'}\n",
      "overlap BPER dev:  set()\n",
      "overlap BPER test:  set()\n",
      "overlap IPER train:  {'Elias', 'Masood', 'John', 'Katie'}\n",
      "overlap IPER dev:  {'Allan'}\n",
      "overlap IPER test:  {'Kim'}\n"
     ]
    }
   ],
   "source": [
    "print(\"overlap loc train: \", train_tokens & ME_LOC_tokens)\n",
    "print(\"overlap loc dev: \", dev_tokens & ME_LOC_tokens)\n",
    "print(\"overlap loc test: \", test_tokens & ME_LOC_tokens)\n",
    "\n",
    "print(\"overlap org train: \", train_tokens & ME_ORG_tokens)\n",
    "print(\"overlap org dev: \", dev_tokens & ME_ORG_tokens)\n",
    "print(\"overlap org test: \", test_tokens & ME_ORG_tokens)\n",
    "\n",
    "print(\"overlap BPER train: \", train_tokens & ME_BPER_tokens)\n",
    "print(\"overlap BPER dev: \", dev_tokens & ME_BPER_tokens)\n",
    "print(\"overlap BPER test: \", test_tokens & ME_BPER_tokens)\n",
    "\n",
    "print(\"overlap IPER train: \", train_tokens & ME_IPER_tokens)\n",
    "print(\"overlap IPER dev: \", dev_tokens & ME_IPER_tokens)\n",
    "print(\"overlap IPER test: \", test_tokens & ME_IPER_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before ME_BPER_tokens: 735\n",
      "Updated ME_BPER_tokens: 733\n",
      "before ME_IPER_tokens: 1029\n",
      "Updated ME_IPER_tokens: 1023\n"
     ]
    }
   ],
   "source": [
    "print(\"before ME_BPER_tokens:\", len(ME_BPER_tokens))\n",
    "updated_ME_BPER = list(ME_BPER_tokens - (train_tokens & ME_BPER_tokens) - (dev_tokens & ME_BPER_tokens) - (test_tokens & ME_BPER_tokens))\n",
    "print(\"Updated ME_BPER_tokens:\", len(updated_ME_BPER))\n",
    "\n",
    "print(\"before ME_IPER_tokens:\", len(ME_IPER_tokens))\n",
    "updated_ME_IPER = list(ME_IPER_tokens - (train_tokens & ME_IPER_tokens) - (dev_tokens & ME_IPER_tokens) - (test_tokens & ME_IPER_tokens))\n",
    "print(\"Updated ME_IPER_tokens:\", len(updated_ME_IPER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ME_LOC: 481\n",
      "After ME_LOC: 470\n"
     ]
    }
   ],
   "source": [
    "# Define the overlap set (tokens from train, dev, and test)\n",
    "dataset_spans = train_tokens | dev_tokens | test_tokens  # Combine all three sets (train, dev, test)\n",
    "\n",
    "# Step 3: Remove overlapping entries from ME_LOC\n",
    "filtered_ME_LOC = []\n",
    "for item in ME_LOC:\n",
    "    entity_string = ' '.join(item['tokens'])  # Join tokens into span string\n",
    "    if entity_string not in dataset_spans:    # Keep only if it's NOT overlapping\n",
    "        filtered_ME_LOC.append(item)\n",
    "\n",
    "# Step 4: Optional check\n",
    "print(\"Before ME_LOC:\", len(ME_LOC))\n",
    "print(\"After ME_LOC:\", len(filtered_ME_LOC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ME_ORG: 427\n",
      "After ME_ORG: 426\n",
      "[{'tokens': ['Saudi', 'Aramco'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Saudi', 'National', 'Bank'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['International', 'Holding', 'Company'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['QNB', 'Group'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['First', 'Abu', 'Dhabi', 'Bank'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Emirates', 'NBD'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['alrajhi', 'bank'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['TAQA', 'Group'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Saudi', 'Electricity', 'Company'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Kuwait', 'Finance', 'House'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['stc', 'Group'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['ADNOC', 'Gas'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['e&'], 'ner_tags': ['B-ORG']}, {'tokens': ['ADCB', 'Group'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Alpha', 'Dhabi', 'Holding'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['National', 'Bank', 'of', 'Kuwait'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Riyad', 'Bank'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Dubai', 'Electricity', 'and', 'Water', 'Authority'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Saudi', 'Awwal', 'Bank'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Emaar', 'Properties'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Dubai', 'Islamic', 'Bank'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Alinma', 'Bank'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Mashreq'], 'ner_tags': ['B-ORG']}, {'tokens': ['Banque', 'Saudi', 'Fransi'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Saudi', 'Arabian', 'Mining', 'Company'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['arab', 'national', 'bank'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Abu', 'Dhabi', 'Islamic', 'Bank'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Attijariwafa', 'bank', 'group'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Qatar', 'Islamic', 'Bank'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Aldar', 'Properties'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Ooredoo', 'Group'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Borouge'], 'ner_tags': ['B-ORG']}, {'tokens': ['Industries', 'Qatar'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Zain', 'Group'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Bank', 'Albilad'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Arab', 'Bank'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Emaar', 'Development'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Commercial', 'Bank'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Almarai'], 'ner_tags': ['B-ORG']}, {'tokens': ['Etihad', 'Etisalat', 'Company'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['SABIC', 'Agri-Nutrients', 'Company'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['BCP', 'Group'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Masraf', 'Al', 'Rayan'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['ACWA', 'Power'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Commercial', 'Bank', 'of', 'Dubai'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['AD', 'Ports', 'Group'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Emirates', 'Islamic'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Bank', 'Muscat'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Commercial', 'International', 'Bank'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Maroc', 'Telecom'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['PureHealth', 'Holding'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Savola', 'Group'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Saudi', 'Investment', 'Bank'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Bank', 'Of', 'Africa'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['NMDC', 'Group'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Omantel'], 'ner_tags': ['B-ORG']}, {'tokens': ['Dr.', 'Sulaiman', 'Al', 'Habib', 'Medical', 'Services', 'Group'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Dukhan', 'Bank'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Emirates', 'Integrated', 'Telecommunications', 'Company'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Aluminium', 'Bahrain'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Boubyan', 'Bank'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Bank', 'AlJazira'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Agility'], 'ner_tags': ['B-ORG']}, {'tokens': ['National', 'Shipping', 'Company', 'of', 'Saudi', 'Arabia'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Fertiglobe'], 'ner_tags': ['B-ORG']}, {'tokens': ['Bupa', 'Arabia'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['National', 'Bank', 'of', 'Ras', 'Al', 'Khaimah'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Sahara', 'International', 'Petrochemical', 'Company'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Kuwait', 'Projects', 'Company'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['solutions', 'by', 'stc'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Nakilat'], 'ner_tags': ['B-ORG']}, {'tokens': ['Qatar', 'Fuel'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['The', 'Company', 'for', 'Cooperative', 'Insurance'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Qatar', 'International', 'Islamic', 'Bank'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Zain', 'KSA'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Gulf', 'Bank'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Saudi', 'Aramco', 'Base', 'Oil', 'Company'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Kingdom', 'Holding', 'Company'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Jordan', 'Phosphate', 'Mines', 'Company'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Elm'], 'ner_tags': ['B-ORG']}, {'tokens': ['Bank', 'ABC'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al-Tijari'], 'ner_tags': ['B-ORG']}, {'tokens': ['QEWC'], 'ner_tags': ['B-ORG']}, {'tokens': ['Air', 'Arabia'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['National', 'Bank', 'of', 'Fujairah'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Burgan', 'Bank', 'Group'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['QNB', 'ALAHLI'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Ahlibank'], 'ner_tags': ['B-ORG']}, {'tokens': ['NBB', 'Group'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Marafiq'], 'ner_tags': ['B-ORG']}, {'tokens': ['Doha', 'Bank'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Sharjah', 'Islamic', 'Bank'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Americana', 'Restaurants'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al', 'Ahli', 'Bank', 'of', 'Kuwait'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Qatar', 'Insurance', 'Company'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Dubai', 'Investments'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['ADES', 'Holding'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['360VUZ'], 'ner_tags': ['B-ORG']}, {'tokens': ['3ayez'], 'ner_tags': ['B-ORG']}, {'tokens': ['Abjjad'], 'ner_tags': ['B-ORG']}, {'tokens': ['Ajeer'], 'ner_tags': ['B-ORG']}, {'tokens': ['AKKASA'], 'ner_tags': ['B-ORG']}, {'tokens': ['Altibbi'], 'ner_tags': ['B-ORG']}, {'tokens': ['Amal', 'Glass'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['ArabiaWeather'], 'ner_tags': ['B-ORG']}, {'tokens': ['Arabot'], 'ner_tags': ['B-ORG']}, {'tokens': ['Aumet'], 'ner_tags': ['B-ORG']}, {'tokens': ['AvidBeam'], 'ner_tags': ['B-ORG']}, {'tokens': ['BulkWhiz'], 'ner_tags': ['B-ORG']}, {'tokens': ['Careem'], 'ner_tags': ['B-ORG']}, {'tokens': ['Chefaa'], 'ner_tags': ['B-ORG']}, {'tokens': ['Dabchy'], 'ner_tags': ['B-ORG']}, {'tokens': ['Daraty'], 'ner_tags': ['B-ORG']}, {'tokens': ['Derq'], 'ner_tags': ['B-ORG']}, {'tokens': ['Elves'], 'ner_tags': ['B-ORG']}, {'tokens': ['Epilert'], 'ner_tags': ['B-ORG']}, {'tokens': ['Fetchr'], 'ner_tags': ['B-ORG']}, {'tokens': ['GoEjaza'], 'ner_tags': ['B-ORG']}, {'tokens': ['HalalaH'], 'ner_tags': ['B-ORG']}, {'tokens': ['ibTECHar', 'Digital', 'Solutions'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Inagrab'], 'ner_tags': ['B-ORG']}, {'tokens': ['Jamalon'], 'ner_tags': ['B-ORG']}, {'tokens': ['Kharabeesh'], 'ner_tags': ['B-ORG']}, {'tokens': ['Lamsa'], 'ner_tags': ['B-ORG']}, {'tokens': ['Lucidya'], 'ner_tags': ['B-ORG']}, {'tokens': ['Malaeb'], 'ner_tags': ['B-ORG']}, {'tokens': ['Mathaqi'], 'ner_tags': ['B-ORG']}, {'tokens': ['Mawdoo3'], 'ner_tags': ['B-ORG']}, {'tokens': ['Mrsool'], 'ner_tags': ['B-ORG']}, {'tokens': ['Nabd'], 'ner_tags': ['B-ORG']}, {'tokens': ['Sarwa'], 'ner_tags': ['B-ORG']}, {'tokens': ['Shamsina'], 'ner_tags': ['B-ORG']}, {'tokens': ['Solfeh'], 'ner_tags': ['B-ORG']}, {'tokens': ['Souqalmal'], 'ner_tags': ['B-ORG']}, {'tokens': ['Swvl'], 'ner_tags': ['B-ORG']}, {'tokens': ['Tamatem'], 'ner_tags': ['B-ORG']}, {'tokens': ['Tarjama'], 'ner_tags': ['B-ORG']}, {'tokens': ['Unifonic'], 'ner_tags': ['B-ORG']}, {'tokens': ['ViaVii'], 'ner_tags': ['B-ORG']}, {'tokens': ['Wasla'], 'ner_tags': ['B-ORG']}, {'tokens': ['Wikaya'], 'ner_tags': ['B-ORG']}, {'tokens': ['Yallacompare'], 'ner_tags': ['B-ORG']}, {'tokens': ['ZenHR', 'Solutions'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Polisario', 'Front'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Arab', 'Democratic', 'Nasserist', 'Party'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Popular', 'Movement', 'in', 'Iraq'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Balad', 'Party'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Istiqlal', 'Party'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Palestinian', 'Liberation', 'Front'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Arab', 'Socialist', 'Union', 'Party', 'of', 'Syria'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['National', 'Covenant', 'Party'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Arab', 'Socialist', \"Ba'ath\", 'Party'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Echorouk'], 'ner_tags': ['B-ORG']}, {'tokens': ['El', 'Heddaf'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Akhbar', 'Al', 'Khaleej'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Al', 'Ayam'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al', 'Watan'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al-Ahram'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al', 'Shorouk'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Kayhan', 'Al', 'Arabi'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Al', 'Anbaa'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al', 'Mada'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al-Mashriq'], 'ner_tags': ['B-ORG']}, {'tokens': ['Ad-Dustour'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al', 'Anbat'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al-Arab', 'Al-Yawm'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Assabeel'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al-Anbaa'], 'ner_tags': ['B-ORG']}, {'tokens': ['al-Qabas'], 'ner_tags': ['B-ORG']}, {'tokens': ['al-Watan'], 'ner_tags': ['B-ORG']}, {'tokens': ['Ad', 'Diyar'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al-Nahar'], 'ner_tags': ['B-ORG']}, {'tokens': ['al-Alam'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al', 'Sharq'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al', 'Madina'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al-Horria'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al', 'Jumhuriya'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al-Thawra'], 'ner_tags': ['B-ORG']}, {'tokens': ['al-Bayan'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al-Ittihad'], 'ner_tags': ['B-ORG']}, {'tokens': ['Gulf', 'News'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Khaleej', 'Times'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Gulf', 'Madhyamam'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Daily', 'Sabah'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al', 'Jamahir'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Tishreen'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al-Wehda'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al-Ouruba'], 'ner_tags': ['B-ORG']}, {'tokens': ['al-Furat'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al', 'Rayaam'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Adaraweesh'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al', 'Eqtisadiah'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al', 'Yaum'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Naseej'], 'ner_tags': ['B-ORG']}, {'tokens': ['Okaz'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al', 'Raya'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['al-Hayat', 'al-Jadida'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al', 'Karmil'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al', 'Manar'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al', 'Massar'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Filasteen', 'al-Muslimah'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Ashabiba'], 'ner_tags': ['B-ORG']}, {'tokens': ['al-Jarida', 'al-Maghribia'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Attajdid'], 'ner_tags': ['B-ORG']}, {'tokens': ['Bayane', 'al-Yaoume'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Akhbar', 'Nouakchott'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['al-Fajr', 'al-Jadid'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['al-Jamahiriyah'], 'ner_tags': ['B-ORG']}, {'tokens': ['al-Zahf', 'Al-Akhdar'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al-Ahd', 'Ul’Jadid'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al', 'Amal'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['al-Balad'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al-Intiqad'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al', 'Kuwaitiya'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al-Kalima'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al-Kifah', 'al-Arabi'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al', 'Liwaa'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al-Massira'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al-Mustaqbal'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al-Waie'], 'ner_tags': ['B-ORG']}, {'tokens': ['Alwasat'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al', 'Rai'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Shihan'], 'ner_tags': ['B-ORG']}, {'tokens': ['Echorouk', 'Group'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['AL24', 'News'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Mekameleen', 'TV'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['El', 'Mehwar'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Cima'], 'ner_tags': ['B-ORG']}, {'tokens': ['DMC'], 'ner_tags': ['B-ORG']}, {'tokens': ['Mazzika'], 'ner_tags': ['B-ORG']}, {'tokens': ['Mazazikh'], 'ner_tags': ['B-ORG']}, {'tokens': ['ONTV'], 'ner_tags': ['B-ORG']}, {'tokens': ['218TV'], 'ner_tags': ['B-ORG']}, {'tokens': ['Arryadia'], 'ner_tags': ['B-ORG']}, {'tokens': ['Athaqafia'], 'ner_tags': ['B-ORG']}, {'tokens': ['Assadissa'], 'ner_tags': ['B-ORG']}, {'tokens': ['MBC'], 'ner_tags': ['B-ORG']}, {'tokens': ['2M'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al', 'Aoula'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['El', 'Hiwar', 'El', 'Tounousi'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Zaytouna', 'TV'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['K24'], 'ner_tags': ['B-ORG']}, {'tokens': ['Khartoum'], 'ner_tags': ['B-ORG']}, {'tokens': ['Omdurman'], 'ner_tags': ['B-ORG']}, {'tokens': ['Tunisna'], 'ner_tags': ['B-ORG']}, {'tokens': ['Roya', 'TV'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al-Mamlaka', 'TV'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Télé', 'Liban'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Iqraa'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al', 'Jazeera'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Al', 'Rayyan'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['beIN', 'SPORTS'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['JoSat'], 'ner_tags': ['B-ORG']}, {'tokens': ['KTV2'], 'ner_tags': ['B-ORG']}, {'tokens': ['One'], 'ner_tags': ['B-ORG']}, {'tokens': ['OTV'], 'ner_tags': ['B-ORG']}, {'tokens': ['LDC'], 'ner_tags': ['B-ORG']}, {'tokens': ['Nagham'], 'ner_tags': ['B-ORG']}, {'tokens': ['NBN'], 'ner_tags': ['B-ORG']}, {'tokens': ['ANB'], 'ner_tags': ['B-ORG']}, {'tokens': ['Hawacom'], 'ner_tags': ['B-ORG']}, {'tokens': ['OSN'], 'ner_tags': ['B-ORG']}, {'tokens': ['Torath'], 'ner_tags': ['B-ORG']}, {'tokens': ['Jawan'], 'ner_tags': ['B-ORG']}, {'tokens': ['PubliTools'], 'ner_tags': ['B-ORG']}, {'tokens': ['Wanasah'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al', 'Tayer', 'Group'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Al', 'Yah', 'Satellite', 'Communications'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Amanat', 'Holdings'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Argaam'], 'ner_tags': ['B-ORG']}, {'tokens': ['Bahrain', 'Islamic', 'Bank'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Baladna'], 'ner_tags': ['B-ORG']}, {'tokens': ['Bayanat'], 'ner_tags': ['B-ORG']}, {'tokens': ['Cerebras'], 'ner_tags': ['B-ORG']}, {'tokens': ['DenizBank'], 'ner_tags': ['B-ORG']}, {'tokens': ['Deyaar'], 'ner_tags': ['B-ORG']}, {'tokens': ['Dnata'], 'ner_tags': ['B-ORG']}, {'tokens': ['Du'], 'ner_tags': ['B-ORG']}, {'tokens': ['Dubai', 'Airports', 'Company'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Emirates', 'Airline'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Emsteel'], 'ner_tags': ['B-ORG']}, {'tokens': ['Fajr', 'Capital'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Flynas'], 'ner_tags': ['B-ORG']}, {'tokens': ['G42'], 'ner_tags': ['B-ORG']}, {'tokens': ['GIB', 'Capital'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Jumeirah', 'Hotels'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Kezad'], 'ner_tags': ['B-ORG']}, {'tokens': ['Kuwait', 'Oil', 'Company'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Ma’aden'], 'ner_tags': ['B-ORG']}, {'tokens': ['Muscat', 'Stock', 'Exchange'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Ooredoo'], 'ner_tags': ['B-ORG']}, {'tokens': ['Shorooq', 'Partners'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Spinneys'], 'ner_tags': ['B-ORG']}, {'tokens': ['Talabat'], 'ner_tags': ['B-ORG']}, {'tokens': ['ADNOC'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al', 'Nabooda', 'Automobiles'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Alshaya'], 'ner_tags': ['B-ORG']}, {'tokens': ['Aster', 'DM', 'Healthcare'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Apparel', 'Group'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Asdaa', 'Burson', 'Marsteller'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Damac'], 'ner_tags': ['B-ORG']}, {'tokens': ['Danube', 'Group'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['DEWA'], 'ner_tags': ['B-ORG']}, {'tokens': ['Empower'], 'ner_tags': ['B-ORG']}, {'tokens': ['Etisalat'], 'ner_tags': ['B-ORG']}, {'tokens': ['The', 'Ghassan', 'Aboud', 'Group'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['GEMS', 'Education'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Henkel', 'GCC'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Marina', 'Home'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Jumeirah', 'Group'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Kharafi', 'Group'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Mubadala'], 'ner_tags': ['B-ORG']}, {'tokens': ['LuLu', 'Group'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Noon'], 'ner_tags': ['B-ORG']}, {'tokens': ['Patchi'], 'ner_tags': ['B-ORG']}, {'tokens': ['Ras', 'Al', 'Khaimah', 'Economic', 'Zone'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Virtuzone'], 'ner_tags': ['B-ORG']}, {'tokens': ['Thumbay', 'Group'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Qatar', 'Charity'], 'ner_tags': ['B-ORG', 'I-ORG']}, {'tokens': ['Emirates', 'Red', 'Crescent'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Islamic', 'Relief', 'Worldwide'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Arab', 'Fund', 'for', 'Economic', 'and', 'Social', 'Development'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Al', 'Quds', 'Association'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['The', 'Khalifa', 'Foundation'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['The', 'Noor', 'Dubai', 'Foundation'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['The', 'Arab', 'Medical', 'Union'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['The', 'Qatar', 'Fund', 'for', 'Development'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['The', 'UAE’s', 'Zayed', 'Giving', 'Initiative'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['The', 'Jordan', 'River', 'Foundation'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['The', 'Palestinian', 'Medical', 'Relief', 'Society'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['The', 'Syrian', 'American', 'Medical', 'Society'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['The', 'International', 'Islamic', 'Charitable', 'Organization'], 'ner_tags': ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG']}, {'tokens': ['Asmidal'], 'ner_tags': ['B-ORG']}, {'tokens': ['Cevital'], 'ner_tags': ['B-ORG']}, {'tokens': ['Djezzy'], 'ner_tags': ['B-ORG']}, {'tokens': ['Naftal'], 'ner_tags': ['B-ORG']}, {'tokens': ['Saidal'], 'ner_tags': ['B-ORG']}, {'tokens': ['SNVI'], 'ner_tags': ['B-ORG']}, {'tokens': ['Sonatrach'], 'ner_tags': ['B-ORG']}, {'tokens': ['Sonalgaz'], 'ner_tags': ['B-ORG']}, {'tokens': ['Banagas'], 'ner_tags': ['B-ORG']}, {'tokens': ['Batelco'], 'ner_tags': ['B-ORG']}, {'tokens': ['BMMI'], 'ner_tags': ['B-ORG']}, {'tokens': ['Investcorp'], 'ner_tags': ['B-ORG']}, {'tokens': ['BiscoMisr'], 'ner_tags': ['B-ORG']}, {'tokens': ['EgyptAir'], 'ner_tags': ['B-ORG']}, {'tokens': ['Egyptalum'], 'ner_tags': ['B-ORG']}, {'tokens': ['eSpace'], 'ner_tags': ['B-ORG']}, {'tokens': ['Mo’men'], 'ner_tags': ['B-ORG']}, {'tokens': ['Nasr'], 'ner_tags': ['B-ORG']}, {'tokens': ['Nilesat'], 'ner_tags': ['B-ORG']}, {'tokens': ['Starworld'], 'ner_tags': ['B-ORG']}, {'tokens': ['Asiacell'], 'ner_tags': ['B-ORG']}, {'tokens': ['Cinescape'], 'ner_tags': ['B-ORG']}, {'tokens': ['Gulfsat'], 'ner_tags': ['B-ORG']}, {'tokens': ['KIPCO'], 'ner_tags': ['B-ORG']}, {'tokens': ['Alrifai'], 'ner_tags': ['B-ORG']}, {'tokens': ['Massaya'], 'ner_tags': ['B-ORG']}, {'tokens': ['PSLab'], 'ner_tags': ['B-ORG']}, {'tokens': ['Tabbah'], 'ner_tags': ['B-ORG']}, {'tokens': ['Libyana'], 'ner_tags': ['B-ORG']}, {'tokens': ['Oilibya'], 'ner_tags': ['B-ORG']}, {'tokens': ['RASCO'], 'ner_tags': ['B-ORG']}, {'tokens': ['Mauritel'], 'ner_tags': ['B-ORG']}, {'tokens': ['Afriquia'], 'ner_tags': ['B-ORG']}, {'tokens': ['Aïcha'], 'ner_tags': ['B-ORG']}, {'tokens': ['Aiguebelle'], 'ner_tags': ['B-ORG']}, {'tokens': ['Akdital'], 'ner_tags': ['B-ORG']}, {'tokens': ['Bimo'], 'ner_tags': ['B-ORG']}, {'tokens': ['Biougnach'], 'ner_tags': ['B-ORG']}, {'tokens': ['BMCI'], 'ner_tags': ['B-ORG']}, {'tokens': ['Colorado'], 'ner_tags': ['B-ORG']}, {'tokens': ['Comarit'], 'ner_tags': ['B-ORG']}, {'tokens': ['Eco-Médias'], 'ner_tags': ['B-ORG']}, {'tokens': ['Electroplanet'], 'ner_tags': ['B-ORG']}, {'tokens': ['Ferrimaroc'], 'ner_tags': ['B-ORG']}, {'tokens': ['Hawaï'], 'ner_tags': ['B-ORG']}, {'tokens': ['Inwi'], 'ner_tags': ['B-ORG']}, {'tokens': ['Jet4you'], 'ner_tags': ['B-ORG']}, {'tokens': ['Koutoubia'], 'ner_tags': ['B-ORG']}, {'tokens': ['Kitea'], 'ner_tags': ['B-ORG']}, {'tokens': ['Laraki'], 'ner_tags': ['B-ORG']}, {'tokens': ['Managem'], 'ner_tags': ['B-ORG']}, {'tokens': ['Marjane'], 'ner_tags': ['B-ORG']}, {'tokens': ['MarsaMaroc'], 'ner_tags': ['B-ORG']}, {'tokens': ['Mondair'], 'ner_tags': ['B-ORG']}, {'tokens': ['Nareva'], 'ner_tags': ['B-ORG']}, {'tokens': ['ONCF'], 'ner_tags': ['B-ORG']}, {'tokens': ['SGTM'], 'ner_tags': ['B-ORG']}, {'tokens': ['Siera'], 'ner_tags': ['B-ORG']}, {'tokens': ['Siger'], 'ner_tags': ['B-ORG']}, {'tokens': ['SNRT'], 'ner_tags': ['B-ORG']}, {'tokens': ['Somaca'], 'ner_tags': ['B-ORG']}, {'tokens': ['SOMED'], 'ner_tags': ['B-ORG']}, {'tokens': ['Sonasid'], 'ner_tags': ['B-ORG']}, {'tokens': ['Sopriam'], 'ner_tags': ['B-ORG']}, {'tokens': ['TGCC'], 'ner_tags': ['B-ORG']}, {'tokens': ['Kahramaa'], 'ner_tags': ['B-ORG']}, {'tokens': ['Nehmeh'], 'ner_tags': ['B-ORG']}, {'tokens': ['RasGas'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al-Bilad'], 'ner_tags': ['B-ORG']}, {'tokens': ['Al-Muhaidib'], 'ner_tags': ['B-ORG']}, {'tokens': ['Aramco'], 'ner_tags': ['B-ORG']}, {'tokens': ['Arasco'], 'ner_tags': ['B-ORG']}, {'tokens': ['Bahri'], 'ner_tags': ['B-ORG']}, {'tokens': ['Dussur'], 'ner_tags': ['B-ORG']}, {'tokens': ['Kudu'], 'ner_tags': ['B-ORG']}, {'tokens': ['Mobily'], 'ner_tags': ['B-ORG']}, {'tokens': ['Nadec'], 'ner_tags': ['B-ORG']}, {'tokens': ['Qaym'], 'ner_tags': ['B-ORG']}, {'tokens': ['Rezayat'], 'ner_tags': ['B-ORG']}, {'tokens': ['SAMI'], 'ner_tags': ['B-ORG']}, {'tokens': ['Saudia'], 'ner_tags': ['B-ORG']}, {'tokens': ['Sawani'], 'ner_tags': ['B-ORG']}, {'tokens': ['Sela'], 'ner_tags': ['B-ORG']}, {'tokens': ['Shawarmer'], 'ner_tags': ['B-ORG']}, {'tokens': ['Xenel'], 'ner_tags': ['B-ORG']}, {'tokens': ['Bakdash'], 'ner_tags': ['B-ORG']}, {'tokens': ['Syriatel'], 'ner_tags': ['B-ORG']}, {'tokens': ['Adwya'], 'ner_tags': ['B-ORG']}, {'tokens': ['Evertek'], 'ner_tags': ['B-ORG']}, {'tokens': ['Monoprix'], 'ner_tags': ['B-ORG']}, {'tokens': ['Nouvelair'], 'ner_tags': ['B-ORG']}, {'tokens': ['Tunisavia'], 'ner_tags': ['B-ORG']}, {'tokens': ['Vermeg'], 'ner_tags': ['B-ORG']}, {'tokens': ['Wallyscar'], 'ner_tags': ['B-ORG']}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3: Remove overlapping entries from ME_LOC\n",
    "filtered_ME_ORG = []\n",
    "for item in ME_ORG:\n",
    "    entity_string = ' '.join(item['tokens'])  # Join tokens into span string\n",
    "    if entity_string not in dataset_spans:    # Keep only if it's NOT overlapping\n",
    "        filtered_ME_ORG.append(item)\n",
    "\n",
    "# Step 4: Optional check\n",
    "print(\"Before ME_ORG:\", len(ME_ORG))\n",
    "print(\"After ME_ORG:\", len(filtered_ME_ORG))\n",
    "print(filtered_ME_ORG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_ME_LOC = collect_entity_strings(filtered_ME_LOC, target_label_prefix = \"B-LOC\")\n",
    "\n",
    "#filtered_ME_ORG = collect_entity_strings(filtered_ME_ORG, target_label_prefix = \"B-ORG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"overlap loc train: \", train_tokens & filtered_ME_LOC)\n",
    "#print(\"overlap loc dev: \", dev_tokens & filtered_ME_LOC)\n",
    "#print(\"overlap loc test: \", test_tokens & filtered_ME_LOC)\n",
    "\n",
    "#print(\"overlap org train: \", train_tokens & filtered_ME_ORG)\n",
    "#print(\"overlap org dev: \", dev_tokens & filtered_ME_ORG)\n",
    "#print(\"overlap org test: \", test_tokens & filtered_ME_ORG)\n",
    "\n",
    "#print(\"overlap BPER train: \", train_tokens & set(updated_ME_BPER))\n",
    "#print(\"overlap BPER dev: \", dev_tokens & set(updated_ME_BPER))\n",
    "#print(\"overlap BPER test: \", test_tokens & set(updated_ME_BPER))\n",
    "\n",
    "#print(\"overlap IPER train: \", train_tokens & set(updated_ME_IPER))\n",
    "#print(\"overlap IPER dev: \", dev_tokens & set(updated_ME_IPER))\n",
    "#print(\"overlap IPER test: \", test_tokens & set(updated_ME_IPER))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_entities = {\n",
    "    \"LOC\": set(),\n",
    "    \"ORG\": set(),\n",
    "    \"BPER\": set(),\n",
    "    \"IPER\": set()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_aug_replace(dataset, sentence_amount, filtered_ME_LOC = filtered_ME_LOC, filtered_ME_ORG = filtered_ME_ORG,\n",
    "                     updated_ME_BPER = updated_ME_BPER, updated_ME_IPER = updated_ME_IPER, used_entities = used_entities):\n",
    "    \"\"\"\n",
    "    Replaces named entities in a subset of the dataset with new ones, ensuring no reuse across datasets.\n",
    "    \"\"\"\n",
    "    eligible_sentences = [sent for sent in dataset if any(tag not in [\"O\", \"B-MISC\", \"I-MISC\"] for tag in sent[\"ner_tags\"])]\n",
    "    selected_sentences = random.sample(eligible_sentences, min(sentence_amount, len(eligible_sentences)))\n",
    "    modified_dataset = [dict(sent) for sent in dataset]\n",
    "\n",
    "    for sent in modified_dataset:\n",
    "        if sent not in selected_sentences:\n",
    "            continue\n",
    "\n",
    "        i = 0\n",
    "        while i < len(sent[\"tokens\"]):\n",
    "            tag = sent[\"ner_tags\"][i]\n",
    "\n",
    "            if tag == 'B-PER':\n",
    "                available = [p for p in updated_ME_BPER if p not in used_entities[\"BPER\"]]\n",
    "                if available:\n",
    "                    replace = random.choice(available)\n",
    "                    sent[\"tokens\"][i] = replace\n",
    "                    used_entities[\"BPER\"].add(replace)\n",
    "                i += 1\n",
    "\n",
    "            elif tag == 'I-PER':\n",
    "                available = [p for p in updated_ME_IPER if p not in used_entities[\"IPER\"]]\n",
    "                if available:\n",
    "                    replace = random.choice(available)\n",
    "                    sent[\"tokens\"][i] = replace\n",
    "                    used_entities[\"IPER\"].add(replace)\n",
    "                i += 1\n",
    "\n",
    "            elif tag == 'B-LOC':\n",
    "                span_start = i\n",
    "                span_len = 1\n",
    "                i += 1\n",
    "                while i < len(sent[\"ner_tags\"]) and sent[\"ner_tags\"][i] == \"I-LOC\":\n",
    "                    span_len += 1\n",
    "                    i += 1\n",
    "\n",
    "                available = [loc for loc in filtered_ME_LOC if tuple(loc[\"tokens\"]) not in used_entities[\"LOC\"] and len(loc[\"tokens\"]) == span_len]\n",
    "                if available:\n",
    "                    replace = random.choice(available)\n",
    "                    sent[\"tokens\"][span_start:span_start + span_len] = replace[\"tokens\"]\n",
    "                    used_entities[\"LOC\"].add(tuple(replace[\"tokens\"]))\n",
    "\n",
    "            elif tag == 'B-ORG':\n",
    "                span_start = i\n",
    "                span_len = 1\n",
    "                i += 1\n",
    "                while i < len(sent[\"ner_tags\"]) and sent[\"ner_tags\"][i] == \"I-ORG\":\n",
    "                    span_len += 1\n",
    "                    i += 1\n",
    "\n",
    "                available = [org for org in filtered_ME_ORG if tuple(org[\"tokens\"]) not in used_entities[\"ORG\"] and len(org[\"tokens\"]) == span_len]\n",
    "                if available:\n",
    "                    replace = random.choice(available)\n",
    "                    sent[\"tokens\"][span_start:span_start + span_len] = replace[\"tokens\"]\n",
    "                    used_entities[\"ORG\"].add(tuple(replace[\"tokens\"]))\n",
    "\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "    return modified_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['Hvor', 'kommer', 'julemanden', 'fra', '?'], 'ner_tags': ['O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Flertallet', 'lever', 'stadig', 'under', 'plastikstykker', 'eller', 'tæpper', ',', 'som', 'de', 'har', 'spændt', 'ud', 'over', 'nogle', 'stokke', 'som', 'et', 'improviseret', 'telt', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Kelds', 'oplæg', 'blev', 'fulgt', '100', 'procent', ',', '\"', 'pointerer', 'Susan', 'Mackensie', '.'], 'ner_tags': ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O'], 'tag_ids': [7, 2, 2, 2, 2, 2, 2, 2, 2, 7, 5, 2]}\n",
      "{'tokens': ['Raki', 'fortyndes', 'med', 'vand', 'og', 'får', 'et', 'uskyldigt', 'mælkeagtigt', 'udseende', ',', 'som', 'man', 'dog', 'ikke', 'skal', 'lade', 'sig', 'narre', 'af', '!'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['H.L.', 'Hansen', 'var', 'en', 'udsædvanlig', 'og', 'frodig', 'personlighed', '.'], 'ner_tags': ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [7, 5, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Og', 'så', 'skal', 'de', 'ellers', 'inden', '3.', 'maj', 'have', 'udarbejdet', 'en', 'ny', 'standardkontrakt', 'og', 'et', 'andet', 'transfersystem', 'til', 'afløsning', 'for', 'det', ',', 'der', 'blev', 'vedtaget', 'på', 'DBUs', 'repræsentantskabsmøde', ',', 'og', 'som', 'spillerne', 'mener', 'giver', 'dem', 'urimelige', 'vilkår', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Søstre', 'kender', 'hinandens', 'inderste', 'på', 'en', 'måde', 'som', 'ingen', 'anden', 'kender', 'dem', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Han', 'kiggede', 'nysgerrigt', 'på', 'mig', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Kyllingerne', 'her', 'har', 'meget', 'mere', 'plads', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['\"', 'Vi', 'fralægger', 'os', 'ethvert', 'ansvar', 'for', 'mordene', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['\"', 'H.', 'C.', 'Andersen', 'er', 'jo', 'verdensberømt', ',', 'fordi', 'hans', 'forfatterskab', 'er', 'blevet', 'oversat', 'til', 'alle', 'sprog', '.'], 'ner_tags': ['O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 7, 5, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Det', 'er', 'absolut', 'nødvendigt', 'med', 'en', 'diskussion', 'om', 'hovedstadsregionens', 'styre', ',', 'men', 'foreløbig', 'har', 'bidragene', 'næsten', 'til', 'det', 'ulidelige', 'været', 'domineret', 'af', 'uopfindsomhed', 'og', 'manglende', 'vilje', 'til', 'fornyelse', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Kører', 'man', 'mange', 'lange', 'ture', ',', 'bør', 'man', 'vælge', 'en', 'bil', 'med', 'motor', 'i', '1,6-', '1,8-', 'eller', '2-liters', 'klasse', ',', 'fordi', 'ekstra', 'motorkraft', 'også', 'betyder', 'ringere', 'støjniveau', 'og', 'øget', 'overhalingssikkerhed', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Kronprins', 'Frederik', 'og', 'prins', 'Joachim', ',', 'der', 'i', 'denne', 'weekend', 'kommer', 'hjem', 'fra', 'Malaysia', ',', 'hvor', 'de', 'har', 'været', 'på', 'ferie', 'med', 'deres', 'far', 'prins', 'Henrik', ',', 'skal', 'også', 'med', 'til', 'ballet', '.'], 'ner_tags': ['O', 'B-PER', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 7, 2, 2, 7, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Hej', 'til', 'Bente', 'som', 'jeg', 'ved', 'læser', 'De', 'Grå', 'Sider', ',', 'og', 'hej', 'til', 'Susan', ',', 'som', 'kender', 'denne', 'historie', ',', 'og', 'ikke', 'har', 'nogen', 'indvendinger', '.'], 'ner_tags': ['O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 7, 2, 2, 2, 2, 6, 8, 8, 2, 2, 2, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['\"', 'Se', 'lige', 'frem', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2]}\n",
      "{'tokens': ['\"', 'Han', 'skulle', \"ha'\", 'en', 'lærestreg', 'for', 'alle', 'de', 'rædsler', ',', 'han', 'har', 'begået', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Hun', 'må', 'have', 'handlet', 'af', 'kærlighed', 'til', 'dig', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['-', 'Hvad', 'er', 'det', ',', 'du', 'siger', '?'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Med', 'andre', 'ord', ':', 'tobaksrygning', 'er', 'forbudt', 'i', 'ministerbilerne', '!'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['At', 'være', 'en', 'hvid', 'er', 'slemt', '-', 'PI', 'for', 'politically', 'incorrect', '-', 'men', 'at', 'være', 'hvid', 'mand', 'er', 'nok', 'noget', 'af', 'det', 'værste', ',', 'man', 'kan', 'være', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['2.', '-', 'Jeg', 'ville', 'nok', 'få', 'foretaget', 'en', 'ansigtsløftning', 'på', 'et', 'tidspunkt', ',', 'eller', 'hvis', 'jeg', 'nogen', 'sinde', 'får', 'en', 'ølmave', ',', 'så', 'vil', 'jeg', 'have', 'suget', 'den', 'væk', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['KTAS-ledelsen', 'burde', 'forstå', ',', 'at', 'denne', 'taktik', '-', '\"', 'fremad', 'drenge', ',', 'jeg', 'kommer', 'straks', '\"', '-', 'kun', 'virker', ',', 'når', 'man', 'ikke', 'møder', 'alvorlig', 'opposition', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Hun', 'smækker', 'kuffertlåget', 'i', 'og', 'undgår', 'med', 'nød', 'og', 'næppe', 'at', 'få', 'fingrene', 'i', 'klemme', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Og', 'nu', 'da', 'hendes', 'søn', 'er', 'kommet', 'i', 'offentlighedens', 'søgelys', ',', 'har', 'jeg', 'endelig', 'indhentet', 'de', 'oplysninger', 'om', 'hende', ',', 'der', 'får', 'de', 'manglende', 'brikker', 'i', 'hendes', 'biografiske', 'mosaik', 'til', 'at', 'falde', 'på', 'plads', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Folmer', 'Svane', 'nikkede', '.'], 'ner_tags': ['B-PER', 'I-PER', 'O', 'O'], 'tag_ids': [7, 5, 2, 2]}\n",
      "{'tokens': ['(', 'Lørdag', 'aften', ')'], 'ner_tags': ['O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2]}\n",
      "{'tokens': ['Ryger', 'vi', 'ud', 'mod', 'Trabzonspor', '-', 'trods', 'en', 'tilfredsstillende', 'præstation', 'af', 'spillerne', '-', 'kan', 'vi', 'måske', 'bagefter', 'tale', 'os', 'til', 'rette', 'om', 'ekstraordinær', 'betaling', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Et', 'chok', 'i', 'en', 'verden', ',', 'der', 'har', 'været', 'vant', 'til', 'vækst', '-', 'og', 'som', 'regel', 'kraftig', 'vækst', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['\"', 'Åbenbart', '!'], 'ner_tags': ['O', 'O', 'O'], 'tag_ids': [2, 2, 2]}\n",
      "{'tokens': ['Der', 'er', 'ingen', 'forskel', 'på', 'produkternes', 'evne', 'til', 'at', 'modvirke', 'korrosion', '-', 'hverken', 'i', 'små', 'eller', 'store', 'motorer', ',', 'om', 'det', 'så', 'er', 'diesel', 'eller', 'benzin', 'gør', 'ingen', 'forskel', ',', 'ej', 'heller', 'om', 'der', 'er', 'anvendt', 'aluminiums-dele', 'i', 'motoren', '-', 'men', 'da', 'additiverne', ',', 'som', 'modvirker', 'korrosion', ',', 'nedbrydes', ',', 'skal', 'frostvæsken', 'mindst', 'udskiftes', 'hvert', 'andet', 'år', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Flere', 'bank-ansatte', 'forsøgte', 'under', 'generalforsamlingen', 'at', 'opfordre', 'aktionærerne', 'til', 'at', '\"', 'dele', 'sol', 'og', 'vind', 'lige', 'med', 'de', 'ansatte', '.', '\"'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Ansvars-placering'], 'ner_tags': ['O'], 'tag_ids': [2]}\n",
      "{'tokens': ['En', 'valutakrise', 'der', 'skyldes', ',', 'at', 'andre', 'lande', 'ikke', 'på', 'tilsvarende', 'vis', 'har', 'orden', 'i', 'samfundshusholdningen', ',', 'og', 'et', 'valutasystem', ',', 'der', 'tilsyneladende', 'endnu', 'ikke', 'er', 'rustet', 'til', 'at', 'sikre', 'stabilitet', 'på', 'valutamarkederne', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Kriminalpolitiet', 'i', 'Løgstør', 'har', 'endnu', 'ikke', 'kunnet', 'konstatere', ',', 'at', 'manden', 'har', 'søgt', 'lægehjælp', ',', 'og', 'man', 'beder', 'derfor', 'offentligheden', 'om', 'hjælp', 'til', 'at', 'identificere', 'gerningsmanden', '.'], 'ner_tags': ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Jeg', 'burde', 'se', 'på', 'byen', ',', 'men', 'jeg', 'kan', 'ikke', 'samle', 'mig', 'sammen', 'og', 'nøjes', 'med', 'at', 'se', 'velvilligt', 'på', 'en', 'englænder', ',', 'der', 'er', 'kommet', 'for', 'sent', 'til', 'maskinen', 'til', 'Botswana', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2]}\n",
      "{'tokens': ['Men', 'man', \"ka'\", \"sgu'\", 'ikke', 'undvære', 'dem', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Ikke', 'en', 'frynse', 'på', 'hendes', 'gulvtæppe', 'var', 'kommet', 'i', 'uorden', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Træsnit', ',', 'kunstindustri', 'og', 'papirklip', 'fra', 'Japan', 'optager', 'næsten', 'en', 'hel', 'langvæg', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['-', 'Nu', 'danser', 'jeg', 'jazzballet', ',', 'det', 'er', 'så', 'sjovt', 'at', 'være', 'dreng', 'på', 'et', 'dansehold', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n"
     ]
    }
   ],
   "source": [
    "for sent in dev_data[:40]:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['Hvor', 'kommer', 'julemanden', 'fra', '?'], 'ner_tags': ['O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Flertallet', 'lever', 'stadig', 'under', 'plastikstykker', 'eller', 'tæpper', ',', 'som', 'de', 'har', 'spændt', 'ud', 'over', 'nogle', 'stokke', 'som', 'et', 'improviseret', 'telt', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Younes', 'oplæg', 'blev', 'fulgt', '100', 'procent', ',', '\"', 'pointerer', 'Faisal', 'Arab', '.'], 'ner_tags': ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O'], 'tag_ids': [7, 2, 2, 2, 2, 2, 2, 2, 2, 7, 5, 2]}\n",
      "{'tokens': ['Raki', 'fortyndes', 'med', 'vand', 'og', 'får', 'et', 'uskyldigt', 'mælkeagtigt', 'udseende', ',', 'som', 'man', 'dog', 'ikke', 'skal', 'lade', 'sig', 'narre', 'af', '!'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Ola', 'Sawadi', 'var', 'en', 'udsædvanlig', 'og', 'frodig', 'personlighed', '.'], 'ner_tags': ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [7, 5, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Og', 'så', 'skal', 'de', 'ellers', 'inden', '3.', 'maj', 'have', 'udarbejdet', 'en', 'ny', 'standardkontrakt', 'og', 'et', 'andet', 'transfersystem', 'til', 'afløsning', 'for', 'det', ',', 'der', 'blev', 'vedtaget', 'på', 'Deyaar', 'repræsentantskabsmøde', ',', 'og', 'som', 'spillerne', 'mener', 'giver', 'dem', 'urimelige', 'vilkår', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Søstre', 'kender', 'hinandens', 'inderste', 'på', 'en', 'måde', 'som', 'ingen', 'anden', 'kender', 'dem', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Han', 'kiggede', 'nysgerrigt', 'på', 'mig', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Kyllingerne', 'her', 'har', 'meget', 'mere', 'plads', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['\"', 'Vi', 'fralægger', 'os', 'ethvert', 'ansvar', 'for', 'mordene', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['\"', 'Ferhat', 'Shenwa', 'Kamel', 'er', 'jo', 'verdensberømt', ',', 'fordi', 'hans', 'forfatterskab', 'er', 'blevet', 'oversat', 'til', 'alle', 'sprog', '.'], 'ner_tags': ['O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 7, 5, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Det', 'er', 'absolut', 'nødvendigt', 'med', 'en', 'diskussion', 'om', 'hovedstadsregionens', 'styre', ',', 'men', 'foreløbig', 'har', 'bidragene', 'næsten', 'til', 'det', 'ulidelige', 'været', 'domineret', 'af', 'uopfindsomhed', 'og', 'manglende', 'vilje', 'til', 'fornyelse', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Kører', 'man', 'mange', 'lange', 'ture', ',', 'bør', 'man', 'vælge', 'en', 'bil', 'med', 'motor', 'i', '1,6-', '1,8-', 'eller', '2-liters', 'klasse', ',', 'fordi', 'ekstra', 'motorkraft', 'også', 'betyder', 'ringere', 'støjniveau', 'og', 'øget', 'overhalingssikkerhed', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Kronprins', 'Mona', 'og', 'prins', 'Hamed', ',', 'der', 'i', 'denne', 'weekend', 'kommer', 'hjem', 'fra', 'Arar', ',', 'hvor', 'de', 'har', 'været', 'på', 'ferie', 'med', 'deres', 'far', 'prins', 'Khalil', ',', 'skal', 'også', 'med', 'til', 'ballet', '.'], 'ner_tags': ['O', 'B-PER', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 7, 2, 2, 7, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Hej', 'til', 'Bin', 'som', 'jeg', 'ved', 'læser', 'De', 'Grå', 'Sider', ',', 'og', 'hej', 'Karam', 'Susan', ',', 'som', 'kender', 'denne', 'historie', ',', 'og', 'ikke', 'har', 'nogen', 'indvendinger', '.'], 'ner_tags': ['O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 7, 2, 2, 2, 2, 6, 8, 8, 2, 2, 2, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['\"', 'Se', 'lige', 'frem', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2]}\n",
      "{'tokens': ['\"', 'Han', 'skulle', \"ha'\", 'en', 'lærestreg', 'for', 'alle', 'de', 'rædsler', ',', 'han', 'har', 'begået', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Hun', 'må', 'have', 'handlet', 'af', 'kærlighed', 'til', 'dig', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['-', 'Hvad', 'er', 'det', ',', 'du', 'siger', '?'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Med', 'andre', 'ord', ':', 'tobaksrygning', 'er', 'forbudt', 'i', 'ministerbilerne', '!'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['At', 'være', 'en', 'hvid', 'er', 'slemt', '-', 'PI', 'for', 'politically', 'incorrect', '-', 'men', 'at', 'være', 'hvid', 'mand', 'er', 'nok', 'noget', 'af', 'det', 'værste', ',', 'man', 'kan', 'være', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['2.', '-', 'Jeg', 'ville', 'nok', 'få', 'foretaget', 'en', 'ansigtsløftning', 'på', 'et', 'tidspunkt', ',', 'eller', 'hvis', 'jeg', 'nogen', 'sinde', 'får', 'en', 'ølmave', ',', 'så', 'vil', 'jeg', 'have', 'suget', 'den', 'væk', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['KTAS-ledelsen', 'burde', 'forstå', ',', 'at', 'denne', 'taktik', '-', '\"', 'fremad', 'drenge', ',', 'jeg', 'kommer', 'straks', '\"', '-', 'kun', 'virker', ',', 'når', 'man', 'ikke', 'møder', 'alvorlig', 'opposition', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Hun', 'smækker', 'kuffertlåget', 'i', 'og', 'undgår', 'med', 'nød', 'og', 'næppe', 'at', 'få', 'fingrene', 'i', 'klemme', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Og', 'nu', 'da', 'hendes', 'søn', 'er', 'kommet', 'i', 'offentlighedens', 'søgelys', ',', 'har', 'jeg', 'endelig', 'indhentet', 'de', 'oplysninger', 'om', 'hende', ',', 'der', 'får', 'de', 'manglende', 'brikker', 'i', 'hendes', 'biografiske', 'mosaik', 'til', 'at', 'falde', 'på', 'plads', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Sanaa', 'Al zuben', 'nikkede', '.'], 'ner_tags': ['B-PER', 'I-PER', 'O', 'O'], 'tag_ids': [7, 5, 2, 2]}\n",
      "{'tokens': ['(', 'Lørdag', 'aften', ')'], 'ner_tags': ['O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2]}\n",
      "{'tokens': ['Ryger', 'vi', 'ud', 'mod', 'Electroplanet', '-', 'trods', 'en', 'tilfredsstillende', 'præstation', 'af', 'spillerne', '-', 'kan', 'vi', 'måske', 'bagefter', 'tale', 'os', 'til', 'rette', 'om', 'ekstraordinær', 'betaling', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Et', 'chok', 'i', 'en', 'verden', ',', 'der', 'har', 'været', 'vant', 'til', 'vækst', '-', 'og', 'som', 'regel', 'kraftig', 'vækst', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['\"', 'Åbenbart', '!'], 'ner_tags': ['O', 'O', 'O'], 'tag_ids': [2, 2, 2]}\n",
      "{'tokens': ['Der', 'er', 'ingen', 'forskel', 'på', 'produkternes', 'evne', 'til', 'at', 'modvirke', 'korrosion', '-', 'hverken', 'i', 'små', 'eller', 'store', 'motorer', ',', 'om', 'det', 'så', 'er', 'diesel', 'eller', 'benzin', 'gør', 'ingen', 'forskel', ',', 'ej', 'heller', 'om', 'der', 'er', 'anvendt', 'aluminiums-dele', 'i', 'motoren', '-', 'men', 'da', 'additiverne', ',', 'som', 'modvirker', 'korrosion', ',', 'nedbrydes', ',', 'skal', 'frostvæsken', 'mindst', 'udskiftes', 'hvert', 'andet', 'år', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Flere', 'bank-ansatte', 'forsøgte', 'under', 'generalforsamlingen', 'at', 'opfordre', 'aktionærerne', 'til', 'at', '\"', 'dele', 'sol', 'og', 'vind', 'lige', 'med', 'de', 'ansatte', '.', '\"'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Ansvars-placering'], 'ner_tags': ['O'], 'tag_ids': [2]}\n",
      "{'tokens': ['En', 'valutakrise', 'der', 'skyldes', ',', 'at', 'andre', 'lande', 'ikke', 'på', 'tilsvarende', 'vis', 'har', 'orden', 'i', 'samfundshusholdningen', ',', 'og', 'et', 'valutasystem', ',', 'der', 'tilsyneladende', 'endnu', 'ikke', 'er', 'rustet', 'til', 'at', 'sikre', 'stabilitet', 'på', 'valutamarkederne', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Kriminalpolitiet', 'i', 'Ardeşen', 'har', 'endnu', 'ikke', 'kunnet', 'konstatere', ',', 'at', 'manden', 'har', 'søgt', 'lægehjælp', ',', 'og', 'man', 'beder', 'derfor', 'offentligheden', 'om', 'hjælp', 'til', 'at', 'identificere', 'gerningsmanden', '.'], 'ner_tags': ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Jeg', 'burde', 'se', 'på', 'byen', ',', 'men', 'jeg', 'kan', 'ikke', 'samle', 'mig', 'sammen', 'og', 'nøjes', 'med', 'at', 'se', 'velvilligt', 'på', 'en', 'englænder', ',', 'der', 'er', 'kommet', 'for', 'sent', 'til', 'maskinen', 'til', 'Qorveh', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2]}\n",
      "{'tokens': ['Men', 'man', \"ka'\", \"sgu'\", 'ikke', 'undvære', 'dem', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Ikke', 'en', 'frynse', 'på', 'hendes', 'gulvtæppe', 'var', 'kommet', 'i', 'uorden', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['Træsnit', ',', 'kunstindustri', 'og', 'papirklip', 'fra', 'Japan', 'optager', 'næsten', 'en', 'hel', 'langvæg', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
      "{'tokens': ['-', 'Nu', 'danser', 'jeg', 'jazzballet', ',', 'det', 'er', 'så', 'sjovt', 'at', 'være', 'dreng', 'på', 'et', 'dansehold', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'tag_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n"
     ]
    }
   ],
   "source": [
    "ME_dev = data_aug_replace(dev_data[:40], 40)\n",
    "for sent in ME_dev: \n",
    "    print(sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
